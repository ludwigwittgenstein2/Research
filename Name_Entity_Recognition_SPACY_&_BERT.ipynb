{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ludwigwittgenstein2/Research/blob/master/Name_Entity_Recognition_SPACY_%26_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X63uWyUiNR5q"
      },
      "source": [
        "#Title: Name Entity Recognition using SPACY and BERT model \n",
        "##by Rick Rejeleene\n",
        "\n",
        "Name Entity Recognition (NER) is an Information Extraction task in Natural Language Processing.\n",
        "\n",
        "In this, we approach NER using SPACY and Transformer based Model, BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zui6sh-9t3j"
      },
      "source": [
        "#Objective \n",
        "\n",
        ">a. BERT NER \n",
        "\n",
        ">b. SPACY NER\n",
        "\n",
        "\n",
        ">We compare both with metrics. \n",
        "\n",
        ">c. Results/Publish\n",
        "\n",
        "Paper link: https://docs.google.com/document/d/1cidVb2qUS_9KrUWrzngaxXPADxBz09matYFjx1RhPwY/edit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VacuMzurg3ny"
      },
      "source": [
        "## What dataset are we using for this task? \n",
        "\n",
        "> U.S Census dataset \n",
        "\n",
        "Link for Dataset: https://drive.google.com/drive/folders/1ozzGFfKH2LFz7Gc2RZm6d4s6SYVw0jGb?usp=sharing\n",
        "\n",
        "\n",
        "##How to do Name Entity Recognition on Custom Dataset using SPACY3? \n",
        "\n",
        "1. Dataset \n",
        "2. Spacy Library\n",
        "3. Training\n",
        "\n",
        "First We require to annotate our custom dataset: \n",
        "\n",
        "a. NER Annotator \n",
        "\n",
        "https://tecoholic.github.io/ner-annotator/\n",
        "\n",
        "b. We require our dataset to be in txt file to be uploaded\n",
        "\n",
        "c. In the NER annotator, apply labels that you desire \n",
        "\n",
        "d. Use Export Annotation to export your annotated dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89OQe3RJhbaY"
      },
      "source": [
        "# What's next? \n",
        "\n",
        "a. Once you have your training dataset\n",
        "\n",
        "b. Use Spacy3\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Objective: SPACY NER on custom dataset"
      ],
      "metadata": {
        "id": "k0pTvZ6uEWhN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7-ZlPjbOzJn",
        "outputId": "8fe7e231-dc75-4bee-fde8-427edc93d851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install -U spacy -q\n",
        "!pip install torch\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "fiOsPsBMVxAr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "nlp = spacy.blank(\"en\") # load a new spacy model\n",
        "db = DocBin() # create a DocBin object"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load custom dataset \n",
        "\n",
        "> Upload annotation json dataset\n",
        "\n",
        "> Re-name to training_data.json\n",
        "\n",
        "> Run code"
      ],
      "metadata": {
        "id": "QJKcxq8EEi4X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "arnG4jIiV27G"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "f = open('training_data.json')\n",
        "TRAIN_DATA = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ach9PqEV5UN",
        "outputId": "ae8d115f-0c56-4cd3-e15e-8da71978be5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:00<00:00, 676.25it/s]\n"
          ]
        }
      ],
      "source": [
        "for text, annot in tqdm(TRAIN_DATA['annotations']): \n",
        "    doc = nlp.make_doc(text) \n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents \n",
        "    db.add(doc)\n",
        "\n",
        "db.to_disk(\"./training_data.spacy\") # save the docbin object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QXd6QJnxOVa-"
      },
      "outputs": [],
      "source": [
        "class NerDataset(torch.utils.data.Dataset):\n",
        "  \"\"\"\n",
        "  Custom dataset implementation to get (text,labels) tuples\n",
        "  Inputs:\n",
        "   - df : dataframe with columns [tags, sentence]\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, df):\n",
        "    if not isinstance(df, pd.DataFrame):\n",
        "      raise TypeError('Input should be a dataframe')\n",
        "    \n",
        "    if \"tags\" not in df.columns or \"sentence\" not in df.columns:\n",
        "      raise ValueError(\"Dataframe should contain 'tags' and 'sentence' columns\")\n",
        "\n",
        "     \n",
        "    \n",
        "    tags_list = [i.split() for i in df[\"tags\"].values.tolist()]\n",
        "    texts = df[\"sentence\"].values.tolist()\n",
        "\n",
        "    self.texts = [tokenizer(text, padding = \"max_length\", truncation = True, return_tensors = \"pt\") for text in texts]\n",
        "    self.labels = [match_tokens_labels(text, tags) for text,tags in zip(self.texts, tags_list)]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    batch_text = self.texts[idx]\n",
        "    batch_labels = self.labels[idx]\n",
        "\n",
        "    return batch_text, torch.LongTensor(batch_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1KFT3iXUJHR",
        "outputId": "278f5561-16c4-4ab2-9be1-765d7e0d3d35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
            "install the spacy-transformers package and re-run this command. The config\n",
            "generated now does not use transformers.\u001b[0m\n",
            "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
            "- Language: en\n",
            "- Pipeline: ner\n",
            "- Optimize for: efficiency\n",
            "- Hardware: CPU\n",
            "- Transformer: None\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "! python -m spacy init config config.cfg --lang en --pipeline ner --optimize efficiency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv7YZSLpULyE",
        "outputId": "43c2c44c-f543-4114-9fb9-07d2b53c8453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-11-21 21:27:35,687] [INFO] Set up nlp object from config\n",
            "INFO:spacy:Set up nlp object from config\n",
            "[2022-11-21 21:27:35,708] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "INFO:spacy:Pipeline: ['tok2vec', 'ner']\n",
            "[2022-11-21 21:27:35,716] [INFO] Created vocabulary\n",
            "INFO:spacy:Created vocabulary\n",
            "[2022-11-21 21:27:35,720] [INFO] Finished initializing nlp object\n",
            "INFO:spacy:Finished initializing nlp object\n",
            "[2022-11-21 21:27:36,085] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "INFO:spacy:Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     53.67    0.00    0.00    0.00    0.00\n",
            " 15     200        188.38   3399.76   98.74   98.95   98.53    0.99\n",
            " 34     400         74.59    179.96   99.47   99.58   99.37    0.99\n",
            " 58     600         58.69     70.82  100.00  100.00  100.00    1.00\n",
            " 88     800          8.38      6.39  100.00  100.00  100.00    1.00\n",
            "123    1000         37.82      6.35  100.00  100.00  100.00    1.00\n",
            "167    1200        122.11     57.63  100.00  100.00  100.00    1.00\n",
            "217    1400        118.87     41.06   99.69   99.58   99.79    1.00\n",
            "283    1600         74.87     23.06  100.00  100.00  100.00    1.00\n",
            "357    1800         35.46      6.53  100.00  100.00  100.00    1.00\n",
            "457    2000          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "557    2200        143.39     36.98  100.00  100.00  100.00    1.00\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "model-last\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy train config.cfg --output ./ --paths.train ./training_data.spacy --paths.dev ./training_data.spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "z1zFlEpiUPO8"
      },
      "outputs": [],
      "source": [
        "nlp_ner = spacy.load(\"/content/model-best\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test out addresss from dataset using SPACY\n",
        "\n",
        ">uncomment and add any input for checking"
      ],
      "metadata": {
        "id": "tidiEIUkFsL_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "2iiMSFTCUNRH"
      },
      "outputs": [],
      "source": [
        "#doc = nlp_ner('Mr. Breonia Adam , PhD, QC, \"\t\"513 LANDWYCK LN, FLOWER MOUND ,TX 75028') # input sample text\n",
        "doc = nlp_ner('Mr. Jasper Bauer , Jr, IQCP, 11096 GINGERWOOD WAY, RANCHO CORDOVA ,CA 95670')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#doc = nlp_ner('MS. Lilly Alldredge , Jr, CLIA, 8243 WORMWOOD RD, JACKSONVILLE ,FL 32210')"
      ],
      "metadata": {
        "id": "GwxzSgUNsGOp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#doc = nlp_ner ('Mr. Madelyn Adams , Sr, CLIA, 102 HILLVIEW DR, CLOVERDALE ,CA 95425')"
      ],
      "metadata": {
        "id": "FsH2g7aYtA1u"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results from SPACY NER"
      ],
      "metadata": {
        "id": "M1rI0YoGFx6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#doc = nlp_ner ('Miss Shazia Aman, Sr, Dr, 105 West HillCrest Rock Drive, Little Rock, AR, 72004')"
      ],
      "metadata": {
        "id": "KqbpaRgjtHPP"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "VGLrLhtKWiXw",
        "outputId": "1a97ec7a-3296-4cf1-ea3f-fe4c49a545bc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mr.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PREFIX TITLE </span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jasper\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GIVEN NAME</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bauer\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\"> FAMILY NAME</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jr, IQCP\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SUFFIX TITLE</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    11096 GINGERWOOD WAY,\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PREFIX TITLE </span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    RANCHO\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STREET SUFFIX </span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    CORDOVA ,\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GIVEN NAME</span>\n",
              "</mark>\n",
              "\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    CA\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STATE NAME</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    95670\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STREET NUMBER</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "spacy.displacy.render(doc, style=\"ent\", jupyter=True) # display in Jupyter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Name Entity Recognition using Transformer based models"
      ],
      "metadata": {
        "id": "bCIWStPJF96M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKcNSpY8_awd",
        "outputId": "bd6018cd-8f65-4fb4-bf1b-98df9d867842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "O-OS_lRnipb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "bbdd83aa-f36e-4192-fb82-9d1a68a51c01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('[CLS]', 'O'), ('Mr', 'O'), ('.', 'O'), ('B', 'I-NAME'), ('##re', 'I-NAME'), ('##onia', 'I-NAME'), ('Adam', 'I-NAME'), (',', 'O'), ('PhD', 'O'), (',', 'O'), ('Q', 'O'), ('##C', 'I-ZIP'), (',', 'O'), ('51', 'O'), ('##3', 'O'), ('LA', 'I-ZIP'), ('##ND', 'I-CITY'), ('##W', 'I-CITY'), ('##Y', 'I-CITY'), ('##C', 'I-CITY'), ('##K', 'I-CITY'), ('L', 'O'), ('##N', 'O'), (',', 'O'), ('FL', 'O'), ('##OW', 'O'), ('##ER', 'O'), ('M', 'O'), ('##O', 'O'), ('##UN', 'O'), ('##D', 'O'), (',', 'O'), ('TX', 'I-ZIP'), ('750', 'O'), ('##28', 'O'), ('[SEP]', 'O')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nMR -> Prefix Title\\nBREONIA -> Given Name\\nADAM -> Family Name\\nPHD QC -> Suffix Title\\n513 -> Street Number\\nLANDWYCK -> Street Name\\nLN -> Street Suffix\\nFLOWER MOUND -> City Name\\nTX -> State Name\\n75028 -> Zip Code\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "label_list = [\n",
        "    \"O\",       # Outside of a named entity\n",
        "    \"B-PREFIX\",  # Beginning of a miscellaneous entity right after another miscellaneous entity\n",
        "    \"I-GIVEN\",  # Miscellaneous entity\n",
        "    \"B-FAMILY\",   # Beginning of a person's name right after another person's name\n",
        "    \"I-NAME\",   # Person's name\n",
        "    \"B-STREET\",   # Beginning of an organisation right after another organisation\n",
        "    \"I-CITY\",   # Organisation\n",
        "    \"B-STATE\",   # Beginning of a location right after another location\n",
        "    \"I-ZIP\"    # Location\n",
        "]\n",
        "\n",
        "sequence = \"Mr. Breonia Adam , PhD, QC, \"\t\"513 LANDWYCK LN, FLOWER MOUND ,TX 75028\"\n",
        "\n",
        "# Bit of a hack to get the tokens with the special tokens\n",
        "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sequence)))\n",
        "inputs = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model(inputs)[0]\n",
        "predictions = torch.argmax(outputs, dim=2)\n",
        "\n",
        "print([(token, label_list[prediction]) for token, prediction in zip(tokens, predictions[0].tolist())])\n",
        "\n",
        "\"\"\"\n",
        "MR -> Prefix Title\n",
        "BREONIA -> Given Name\n",
        "ADAM -> Family Name\n",
        "PHD QC -> Suffix Title\n",
        "513 -> Street Number\n",
        "LANDWYCK -> Street Name\n",
        "LN -> Street Suffix\n",
        "FLOWER MOUND -> City Name\n",
        "TX -> State Name\n",
        "75028 -> Zip Code\n",
        "\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/Cleaned_Simple_50.txt', 'r')\n",
        "content = f.read()\n",
        "print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF5NJu1zI8f8",
        "outputId": "88490bf6-0bac-4c9f-c18d-5cc48c2e05fa"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number\tName\tAddress\n",
            "2\t\"Dean. Alex Abadi , Jr, QA, \"\t\"14646 RANCHERO RD, HESPERIA ,CA 92345\"\n",
            "3\t\"Dr. Lyla Abbatiello , Jr, CLIA, \"\t\"517 N MOUNTAIN AVE, # 202, UPLAND ,CA 91786\"\n",
            "4\t\"Mr. Kylia Abbott , Jr, QC, \"\t\"2731 PONKAN MEADOW DR, APOPKA ,FL 32712\"\n",
            "5\t\"Mrs. Bryce Abbott , Jr, QA, \"\t\"237 SAINT TROPEZ LN, LINCOLN ,CA 95648\"\n",
            "6\t\"Ms. Daniela Abella , PhD, IQCP,\"\t\"20054 CHICKEN DR, DECATUR ,AR 72722\"\n",
            "7\t\"Mr. Jacob Abraham , Jr, CLIA, \"\t\"3006 E 17TH ST, # 6, OAKLAND ,CA 94601\"\n",
            "8\t\"Mr. Reily Acevedo , PhD, QC,\"\t\"15123 BROOKHURST ST, APT 357, WESTMINSTER ,CA 92683\"\n",
            "9\t\"Col. Micaela Acevedo , PhD, QA, \"\t\"1724 HORIZON HEIGHTS CIR, EL CAJON ,CA 92019\"\n",
            "10\t\"Mr. Breonia Adam , PhD, QC, \"\t\"513 LANDWYCK LN, FLOWER MOUND ,TX 75028\"\n",
            "11\t\"Mr. Miranda Adam , Jr, QA,\"\t\"3503 E CORNELL ST, LUBBOCK ,TX 79403\"\n",
            "12\t\"Mr. Madelyn Adams , Sr, CLIA\"\t\"102 HILLVIEW DR, CLOVERDALE ,CA 95425\"\n",
            "13\t\"Mr. Jase Adams , PhD, QC, \"\t\"1940 MARKET ST, FERNDALE ,CA 95536\"\n",
            "14\t\"Col. Jessica Adams , PhD, QA, \"\t\"3120 11TH ST SW, LEHIGH ACRES ,FL 33976\"\n",
            "15\t\"Dean. Samuel Adams , Sr, IQCP, \"\t\"11419 SAN MINIATO AVE, BAKERSFIELD ,CA 93312\"\n",
            "16\t\"Dr. Kara Adams , Sr, QC\"\t\"12 CHATHAM CT, SAN JOSE ,CA 95139\"\n",
            "17\t\"Mr. Brittany Adams , Sr, QA,\"\t\"PO BOX 436, PRAIRIE GROVE ,AR 72753\"\n",
            "18\t\"Mrs. Mykenzi Adams , PhD, \"\t\"CLIA, 3902 FM 1653, CANTON ,TX 75103\"\n",
            "19\t\"Ms. Xaivore Adcock , PhD, \"\t\"QC, 7010 ALMOND GREEN DR, SAN ANTONIO ,TX 78250\"\n",
            "20\t\"Mr. Jackson Adeeb , PhD, \"\t\"QA, 2490 CORINTH AVE, APT 3, LOS ANGELES ,CA 90064\"\n",
            "21\t\"Ms. Nicole Adkins , Jr, IQCP, \"\t\"36718 COTTONWOOD ST, WINCHESTER ,CA 92596\"\n",
            "22\t\"Ms. Dalton Agan , Sr, CLIA, \"\t\"1204 NILDA AVE, MOUNTAIN VIEW ,CA 94040\"\n",
            "23\t\"Ms. Brian Aguilar , Sr, QC,\"\t\"481 LESTER AVE, CLOVIS ,CA 93619\"\n",
            "24\t\"Ms. Casey Aguilar , Jr, QA, \"\t\"47-325 BORDEAUX DR, LA QUINTA ,CA 92253\"\n",
            "25\t\"Ms. Janea Aguilera , Jr, QC, \"\t\"5710 ONIA LN, RICHMOND ,TX 77469\"\n",
            "26\t\"Ms. Lucas Ahlbach , Jr, QA, \"\t\"622 SPRINGDALE CIR, PALM SPRINGS ,FL 33461\"\n",
            "27\t\"Dean. Julia Aitken , Sr, CLIA, \"\t\"10 CALLE DE VIDA, RANCHO SANTA MARGARITA ,CA 92688\"\n",
            "28\t\"Dr. Tea Akins , Sr, QC, \"\t\"3107 GALLOWAY OAKS DR, LAKELAND ,FL 33810\"\n",
            "29\t\"Mr. Qais Al-Sabahi , Sr, QA, \"\t\"2808 40TH AVE W, BRADENTON ,FL 34205\"\n",
            "30\t\"Mr. Parsa Alaeddini , Sr, IQCP,\"\t\"311 N ROBERTSON BLVD, # 656, BEVERLY HILLS ,CA 90211\"\n",
            "31\t\"Mr. Carolina Alaniz , Jr, QA, \"\t\"612 28TH ST, RICHMOND ,CA 94804\"\n",
            "32\t\"Dean. Aryanna Albarran , Jr, CLIA, \"\t\"3508 SIMSBURY CT, CARLSBAD ,CA 92010\"\n",
            "33\t\"Dr. Micah Albonico , Sr, QC, \"\t\"2003 KIMBROOK DR, ROUND ROCK ,TX 78681\"\n",
            "34\t\"Mr. Anyssa Alcantar , Jr, QA, \"\t\"1514 OLD ANNETTA RD, ALEDO ,TX 76008\"\n",
            "35\t\"Mr. Alexa Alcon , Jr, IQCP, \"\t\"PO BOX 755, DANVILLE ,CA 94526\"\n",
            "36\t\"Dean. Gracie Aldama , Jr, CLIA, \"\t\"2046 JEWELL LEE LN, PENSACOLA ,FL 32534\"\n",
            "37\t\"Dr. Tristan Alderman , Sr, QC, \"\t\"709 S 3RD AVE, PARAGOULD ,AR 72450\"\n",
            "38\t\"Mr. Jim Aldridge , Sr, QA, \"\t\"6000 63RD TER, PINELLAS PARK ,FL 33781\"\n",
            "39\t\"Mr. Zackry Aldridge , Sr, CLIA, \"\t\"329 S VILLAGE DR, MCKINNEY ,TX 75070\"\n",
            "40\t\"Dean. Ricky Aleman , Jr, QC, \"\t\"10550 BOLSA AVE, APT 19, GARDEN GROVE ,CA 92843\"\n",
            "41\t\"Dr. Daniel Alexander , Jr, QA, \"\t\"21527 BLACK OPAL LN, KINGWOOD ,TX 77339\"\n",
            "42\t\"Ms. Zachary Alexander , Jr, IQCP, \"\t\"6161 NW 44TH TER, COCONUT CREEK ,FL 33073\"\n",
            "43\t\"Ms. Brooke Alexander , Jr, CLIA, \"\t\"36491 YAMAS DR, APT 3205, WILDOMAR ,CA 92595\"\n",
            "44\t\"Ms. Olivia Alexander , Sr, QC, \"\t\"17460 CAMINITO BAYA, SAN DIEGO ,CA 92127\"\n",
            "45\t\"Mr. Mirabella Alexander , Sr, QA, \"\t\"24850 HANCOCK AVE, APT B207, MURRIETA ,CA 92562\"\n",
            "46\t\"Mr. Kyree Alexander , Sr, IQCP, \"\t\"4894 N GEARHART AVE, FRESNO ,CA 93726\"\n",
            "47\t\"Dean. Sonny Alfieri , Jr, CLIA, \"\t\"47085 CHRIS ALLEN WAY, AGUANGA ,CA 92536\"\n",
            "48\t\"Dr. Cathon Alford , Jr, QC, \"\t\"106 HERCULES ST, APT B, SHEPPARD AFB ,TX 76311\"\n",
            "49\t\"Col. Sam Alimentato , PhD, QA,\"\t\"12285 MORRISON ST, MORENO VALLEY ,CA 92555\"\n",
            "50\t\"MS. Lilly Alldredge , Jr, CLIA, \"\t\"8243 WORMWOOD RD, JACKSONVILLE ,FL 32210\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#use if you want to close file\n",
        "f.close()"
      ],
      "metadata": {
        "id": "0d_k05tpJBvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "f = open('/content/Cleaned_Simple_50.txt', 'r')\n",
        "content = f.read()\n",
        "\n",
        "text = content\n",
        "\n",
        "#text = 'Mr. Breonia Adam , PhD, QC, \"\t\"513 LANDWYCK LN, FLOWER MOUND ,TX 75028'\n",
        "\n",
        "tagger = pipeline(task='ner', aggregation_strategy='simple', grouped_entities=True)\n",
        "named_ents = tagger(text)\n",
        "stored_data = pd.DataFrame(named_ents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys9kbRimJDkS",
        "outputId": "56efa847-01e9-418d-e50c-eccc53895949"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/pipelines/token_classification.py:136: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
            "  \"`grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stored_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oqc0tZp5JMXB",
        "outputId": "449e6750-708b-44ba-bc65-80ef8479ad0e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   entity_group     score          word  start   end\n",
            "0           PER  0.597720          Dean     23    27\n",
            "1           PER  0.978966    Alex Abadi     29    39\n",
            "2           PER  0.919571            Jr     42    44\n",
            "3           LOC  0.654975            RA     59    61\n",
            "4           ORG  0.598351    ##NCHERO R     61    69\n",
            "..          ...       ...           ...    ...   ...\n",
            "71          ORG  0.615709             L    988   989\n",
            "72          LOC  0.381800          ##IG    991   993\n",
            "73          ORG  0.581082          ACRE    995   999\n",
            "74          PER  0.996841  Samuel Adams   1022  1034\n",
            "75          PER  0.843554            Sr   1037  1039\n",
            "\n",
            "[76 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#output to a CSV File\n",
        "stored_data.to_csv('TransformerNER.csv', sep='\\t')"
      ],
      "metadata": {
        "id": "YioXSjmqJRaB"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WaetlvTiqJN"
      },
      "source": [
        "# SPACY PARSER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc_B5IImCEXL",
        "outputId": "da0f8502-58b4-49d4-c523-47f1d99a0276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.10.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.28.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqjUaHYfCTJV",
        "outputId": "d781c66c-cf8a-4652-e521-9ac183b7689b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacy_conll\n",
            "  Downloading spacy_conll-3.2.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: spacy>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy_conll) (3.4.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (2.4.5)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (8.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (57.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (2.0.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (1.10.2)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (0.7.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (2.0.7)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (3.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (2.28.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (21.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (4.64.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (1.21.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (0.8.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (3.0.10)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (1.0.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (4.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (2.11.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->spacy_conll) (1.0.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.0.1->spacy_conll) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.0.1->spacy_conll) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.0.1->spacy_conll) (5.2.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->spacy_conll) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->spacy_conll) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->spacy_conll) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->spacy_conll) (2.1.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.0.1->spacy_conll) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.0.1->spacy_conll) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.8.0,>=0.3.0->spacy>=3.0.1->spacy_conll) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.0.1->spacy_conll) (2.0.1)\n",
            "Installing collected packages: spacy-conll\n",
            "Successfully installed spacy-conll-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy_conll "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56VTR7PyCafm",
        "outputId": "80731e35-611e-49f0-8c70-cbfe7ff4c0e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacy-stanza\n",
            "  Downloading spacy_stanza-1.0.2-py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy-stanza) (3.4.3)\n",
            "Collecting stanza<1.5.0,>=1.2.0\n",
            "  Downloading stanza-1.4.2-py3-none-any.whl (691 kB)\n",
            "\u001b[K     |████████████████████████████████| 691 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (57.4.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (1.0.3)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (8.1.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.11.3)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (0.7.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (1.10.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.28.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (4.1.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (3.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (3.0.10)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.4.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (0.10.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (4.64.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (1.0.9)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.0.8)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (21.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<4.0.0,>=3.0.0->spacy-stanza) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.0.0->spacy-stanza) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (2.10)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza<1.5.0,>=1.2.0->spacy-stanza) (1.12.1+cu113)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stanza<1.5.0,>=1.2.0->spacy-stanza) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza<1.5.0,>=1.2.0->spacy-stanza) (3.19.6)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.8.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<4.0.0,>=3.0.0->spacy-stanza) (2.0.1)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=5f97ee359ee09c0ae7cd472c3113bb4d80a257826c50ccd249b2f0a6f57322cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/e3/f2/1de1c2e3ed742e1df73e0f15d58864e50c7e64f607b548d6cf\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, stanza, spacy-stanza\n",
            "Successfully installed emoji-2.2.0 spacy-stanza-1.0.2 stanza-1.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy-stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DucUPFRpCDX6",
        "outputId": "e60f9ad4-53b1-43b5-863c-de6e01d80d63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# sent_id = 1\n",
            "# text = Mr. Jasper Bauer , Jr, IQCP, 11096 GINGERWOOD WAY, RANCHO CORDOVA ,CA 95670\n",
            "1\tMr.\tMr.\tPROPN\tNNP\tNumber=Sing\t0\troot\t_\t_\n",
            "2\tJasper\tJasper\tPROPN\tNNP\tNumber=Sing\t1\tflat\t_\t_\n",
            "3\tBauer\tBauer\tPROPN\tNNP\tNumber=Sing\t1\tflat\t_\t_\n",
            "4\t,\t,\tPUNCT\t,\t_\t1\tpunct\t_\t_\n",
            "5\tJr\tJr\tPROPN\tNNP\tNumber=Sing\t1\tlist\t_\tSpaceAfter=No\n",
            "6\t,\t,\tPUNCT\t,\t_\t1\tpunct\t_\t_\n",
            "7\tIQCP\tIQCP\tPROPN\tNNP\tNumber=Sing\t1\tlist\t_\tSpaceAfter=No\n",
            "8\t,\t,\tPUNCT\t,\t_\t1\tpunct\t_\t_\n",
            "9\t11096\t11096\tNUM\tCD\tNumForm=Digit|NumType=Card\t7\tlist\t_\t_\n",
            "10\tGINGERWOOD\tgingerwood\tNOUN\tNN\tNumber=Sing\t11\tcompound\t_\t_\n",
            "11\tWAY\tway\tNOUN\tNN\tNumber=Sing\t1\tlist\t_\tSpaceAfter=No\n",
            "12\t,\t,\tPUNCT\t,\t_\t1\tpunct\t_\t_\n",
            "13\tRANCHO\tRANCHO\tPROPN\tNNP\tNumber=Sing\t14\tcompound\t_\t_\n",
            "14\tCORDOVA\tCORDOVA\tPROPN\tNNP\tNumber=Sing\t1\tlist\t_\t_\n",
            "15\t,\t,\tPUNCT\t,\t_\t16\tpunct\t_\tSpaceAfter=No\n",
            "16\tCA\tCA\tPROPN\tNNP\tNumber=Sing\t1\tlist\t_\t_\n",
            "17\t95670\t95670\tNUM\tCD\tNumForm=Digit|NumType=Card\t1\tlist\t_\tSpaceAfter=No\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from spacy_conll import init_parser\n",
        "\n",
        "\n",
        "# Initialise English parser, already including the ConllFormatter as a pipeline component.\n",
        "# Indicate that we want to get the CoNLL headers in the string output.\n",
        "# `use_gpu` and `verbose` are specific to stanza. These keywords arguments are passed onto their Pipeline() initialisation\n",
        "nlp = init_parser(\"en\",\n",
        "                  \"stanza\",\n",
        "                  parser_opts={\"use_gpu\": True, \"verbose\": False}, include_headers=True)\n",
        "# Parse a given string\n",
        "doc = nlp(\"Mr. Jasper Bauer , Jr, IQCP, 11096 GINGERWOOD WAY, RANCHO CORDOVA ,CA 95670\")\n",
        "\n",
        "# Get the CoNLL representation of the whole document, including headers\n",
        "conll = doc._.conll_str\n",
        "print(conll)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEtSqIAYl-4k",
        "outputId": "09562da2-e6d4-43a7-e451-675fd1149d40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SPACY HELPER MODEL\n",
            "Base model used:  en_core_web_sm\n",
            "Removed components:  ['parser', 'lemmatizer', 'ner']\n",
            "Enabled components:  ['tok2vec', 'tagger', 'attribute_ruler']\n",
            "\n",
            "DEMO SPACY DOC LIST BUILDING...DONE!\n",
            "\n",
            "CoNLL 2003 CONVERSION:\n",
            "\n",
            "\n",
            "DOC TEXT (NOT included in CoNLL 2003, just for demo):  iPhone X is coming. \n",
            "\n",
            "-DOCSTART- -X- -X- O\n",
            "iPhone NNP NNP B-GADGET\n",
            "X NNP NNP L-GADGET\n",
            "is VBZ VBZ O\n",
            "coming VBG VBG O\n",
            ". . . O\n",
            "\n",
            "DOC TEXT (NOT included in CoNLL 2003, just for demo):  Space X is nice. \n",
            "\n",
            "-DOCSTART- -X- -X- O\n",
            "Space NN NN B-BRAND\n",
            "X NNP NNP L-BRAND\n",
            "is VBZ VBZ O\n",
            "nice JJ JJ O\n",
            ". . . O\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.training import offsets_to_biluo_tags\n",
        "from spacy.tokens import Span\n",
        "\n",
        "print(\"SPACY HELPER MODEL\")\n",
        "base_model = \"en_core_web_sm\"\n",
        "nlp = spacy.load(base_model)\n",
        "to_disable= ['parser', 'lemmatizer', 'ner']\n",
        "_ = [nlp.remove_pipe(item) for item in to_disable]\n",
        "print(\"Base model used: \", base_model)\n",
        "print(\"Removed components: \", to_disable)\n",
        "print(\"Enabled components: \", nlp.pipe_names)\n",
        "\n",
        "# Assume text is already available as sentences...\n",
        "# so no need for spaCy `sentencizer` or similar\n",
        "print(\"\\nDEMO SPACY DOC LIST BUILDING...\", end=\"\")\n",
        "doc1 = nlp(\"iPhone X is coming.\")\n",
        "doc1.ents = [Span(doc1, 0, 2, label=\"GADGET\")]\n",
        "doc2 = nlp(\"Space X is nice.\")\n",
        "doc2.ents = [Span(doc1, 0, 2, label=\"BRAND\")]\n",
        "docs = [doc1, doc2]\n",
        "print(\"DONE!\")\n",
        "\n",
        "print(\"\\nCoNLL 2003 CONVERSION:\\n\")\n",
        "results = []\n",
        "for doc in docs:\n",
        "    # Preliminary: whole sentence\n",
        "    whole_sentence = doc.text\n",
        "    # 1st item (CoNLL 2003): word\n",
        "    words = [token.text for token in doc]\n",
        "    # 2nd item (CoNLL 2003): POS\n",
        "    pos = [token.tag_ for token in doc]\n",
        "    # 3rd item (CoNLL 2003): syntactic chunk tag\n",
        "    # sct = pos  # Redundant, so will be left out\n",
        "    # 4th item (CoNLL 2003): named entities\n",
        "    spacy_entities = [\n",
        "        (ent.start_char, ent.end_char, ent.label_)\n",
        "        for ent in doc.ents\n",
        "    ]\n",
        "    biluo_entities = offsets_to_biluo_tags(doc, spacy_entities)\n",
        "    results.append((whole_sentence, words, pos, biluo_entities))\n",
        "\n",
        "for result in results:\n",
        "    print(\n",
        "        \"\\nDOC TEXT (NOT included in CoNLL 2003, just for demo): \",\n",
        "        result[0], \"\\n\"\n",
        "    )\n",
        "    print(\"-DOCSTART- -X- -X- O\")\n",
        "    for w,x,y,z in zip(result[1], result[2], result[2], result[3]):\n",
        "        print(w,x,y,z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "fdRfB3BFqmkr"
      },
      "outputs": [],
      "source": [
        "def print_entities(pipeline, text):\n",
        "    \n",
        "    # Create a document \n",
        "    document = pipeline(text)\n",
        "    \n",
        "    # Entity text & label extraction\n",
        "    for entity in document.ents:\n",
        "        print(entity.text + '->', entity.label_)\n",
        "        \n",
        "        \n",
        "def visualize_entities(pipeline, text):\n",
        "    \n",
        "    # Create a document \n",
        "    document = pipeline(text)\n",
        "        \n",
        "    # Show entities in pretty manner\n",
        "    displacy.render(document, jupyter=True, style='ent')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQVdMid7LrIx",
        "outputId": "b9256f05-21ed-4be8-da71-956948f9c16d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.1) (3.4.3)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.28.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.8.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.5)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.1.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.21.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.24.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "i5RBLpqorH6e"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "import en_core_web_sm\n",
        "nlp_sm = en_core_web_sm.load()\n",
        "\n",
        "# Load English large model\n",
        "#nlp_sm = spacy.load(\"en_core_web_lg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Fo1qOdbGrQEH"
      },
      "outputs": [],
      "source": [
        "short_text = '“Amy Schneider, an engineering manager from Oakland, California, became the first woman and the fourth person on “Jeopardy!” to earn more than $1 million in winnings on Friday’s episode”.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "i_I8WgKjrUDX"
      },
      "outputs": [],
      "source": [
        "long_text = 'Good news for consumers, undoubtedly, and good news also for investors. Apple’s recent results, covering the three months to December 31 2016, saw the company’s chief financial officer Luca Maestri announce: ‘We returned nearly $15 billion to investors through share re-purchases and dividends during the quarter.’ The quarterly dividend itself was 57 cents a share, identical to the dividend for the previous three quarters and up on the 52 cents paid for each of the four quarters before that.Business is brisk at Apple. On January 31, Tim Cook, Apple’s chief executive, said of the last three months of 2016: ‘We’re thrilled to report that our holiday quarter results generated Apple’s highest quarterly revenue ever, and broke multiple records along the way. We sold more iPhones than ever before and set all-time revenue records for iPhone, Services, Mac and Apple Watch'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "g5pPqd9LrSXv"
      },
      "outputs": [],
      "source": [
        "addresss = \"Dean. Alex Abadi , Jr, QA, \"\t\"14646 RANCHERO RD, HESPERIA ,CA 92345\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ITWJwylrLYo",
        "outputId": "8e7b4e14-0347-4395-b56e-15a3f3563ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amy Schneider-> PERSON\n",
            "Oakland-> GPE\n",
            "California-> GPE\n",
            "first-> ORDINAL\n",
            "fourth-> ORDINAL\n",
            "Jeopardy-> WORK_OF_ART\n",
            "more than $1 million-> MONEY\n",
            "Friday-> DATE\n"
          ]
        }
      ],
      "source": [
        "print_entities(nlp_sm, short_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qrw_17xdsWpX",
        "outputId": "16ec0a06-71cb-458a-e767-7b7521e566cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dean-> PERSON\n",
            "Alex Abadi-> PERSON\n",
            "Jr-> GPE\n",
            "QA-> GPE\n",
            "14646-> DATE\n",
            "RD-> ORG\n",
            "HESPERIA-> ORG\n",
            "CA 92345-> PERSON\n"
          ]
        }
      ],
      "source": [
        "print_entities(nlp_sm, addresss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "hRnGC6ybsZUd",
        "outputId": "6711876f-11b4-4716-9f60-2ffaa69d2815"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Dean\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ". \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Alex Abadi\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jr\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    QA\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    14646\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " RANCHERO \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    RD\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    HESPERIA\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " ,\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    CA 92345\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "visualize_entities(nlp_sm, addresss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "kfKkp5HBm6WO",
        "outputId": "fa407c74-dd56-4dff-bd4d-bf728a87d434"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">“\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Amy Schneider\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", an engineering manager from \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Oakland\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    California\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", became the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    first\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " woman and the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    fourth\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " person on “\n",
              "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jeopardy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
              "</mark>\n",
              "!” to earn \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    more than $1 million\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              " in winnings on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Friday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "’s episode”.</div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "visualize_entities(nlp_sm, short_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBZ2Y6pHoXQ1",
        "outputId": "da574c80-3470-447f-f7fb-f69a5f39ceb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple’s-> ORG\n",
            "the three months to December 31 2016-> DATE\n",
            "Maestri-> PERSON\n",
            "nearly $15 billion-> MONEY\n",
            "the quarter-> DATE\n",
            "quarterly-> DATE\n",
            "57 cents-> MONEY\n",
            "the previous three quarters-> DATE\n",
            "52 cents-> MONEY\n",
            "the four quarters-> DATE\n",
            "Apple-> ORG\n",
            "January 31-> DATE\n",
            "Tim Cook-> PERSON\n",
            "Apple’s-> ORG\n",
            "the last three months of 2016-> DATE\n",
            "our holiday quarter-> DATE\n",
            "Apple-> ORG\n",
            "quarterly-> DATE\n",
            "iPhones-> ORG\n",
            "iPhone, Services,-> ORG\n",
            "Mac-> ORG\n",
            "Apple Watch-> ORG\n"
          ]
        }
      ],
      "source": [
        "print_entities(nlp_sm, long_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "gDmFMhMNipee",
        "outputId": "0f8b8929-7498-41fc-8fde-265168e40511"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">“\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Amy Schneider\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", an engineering manager from \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Oakland\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    California\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", became the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    first\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " woman and the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    fourth\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " person on “\n",
              "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jeopardy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
              "</mark>\n",
              "!” to earn \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    more than $1 million\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              " in winnings on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Friday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "’s episode”.</div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "visualize_entities(nlp_sm, short_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9H-IOv5H7xih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-AMMr0QO7xkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5nOAm0He7xmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sNjnm6gG7xpz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bCIWStPJF96M"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyO8JobLyOVONBnAXtipjkF0",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}