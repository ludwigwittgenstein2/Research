{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwtV3TfhdebFrp8kY1d9/b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ludwigwittgenstein2/Research/blob/master/Novel_Address_Using_LLM_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Title: Novel Address Generation using LLM and GAN\n",
        "### by Rick Rejeleene\n",
        "\n",
        "Generative Models, mostly we are using to generate any artifact [text, audio, video]"
      ],
      "metadata": {
        "id": "5TPG8aeqOqgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First we approach using GPT-2 Model - Why?\n",
        "\n",
        "a. GPT-2 is popular model of recent \n",
        "\n",
        "b. We try to use our dataset on GPT-2\n",
        "\n",
        "c. We try to get results\n",
        "\n",
        "\n",
        "\n",
        "###Goal of the Work: \n",
        "\n",
        "a. Apply Language Model \n",
        "\n",
        "b. Apply GAN or variation of GAN\n",
        "\n",
        "c. Use Census dataset [Name-Address]\n",
        "\n",
        "d. Compare results \n",
        "\n",
        "e. Write Paper/Results\n"
      ],
      "metadata": {
        "id": "UM-vb7aHVSmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install dependencies \n"
      ],
      "metadata": {
        "id": "autIgNm6VvZm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFReNMMTVr-E",
        "outputId": "a1219d92-2321-4821-9d4e-6e1a0b748018"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check GPU "
      ],
      "metadata": {
        "id": "dzd5mjNEO0wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPtg57mOWQCZ",
        "outputId": "c9d29b05-c72a-4754-8732-7622f3557902"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ],
      "metadata": {
        "id": "ukFHoRLJWSXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "metadata": {
        "id": "TK4Vi_24WSdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#upload our own dataset "
      ],
      "metadata": {
        "id": "qSAGpUpEWXFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = '/content/dataset.csv'"
      ],
      "metadata": {
        "id": "6HyenfPdWUT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "metadata": {
        "id": "f40hG69fWUYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Model"
      ],
      "metadata": {
        "id": "UHGjgRlpWdit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "metadata": {
        "id": "5dsfnNRZWcTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "metadata": {
        "id": "LATz4EOfWisl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "metadata": {
        "id": "fv9WgqfAWk7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "metadata": {
        "id": "SgrEnz6QWm1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate our data from Model"
      ],
      "metadata": {
        "id": "eFxYb33RWpQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Consider parameters\n",
        "\n",
        "length: Number of tokens to generate (default 1023, the maximum)\n",
        "temperature: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "top_k: Limits the generated guesses to the top k guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set top_k=40)\n",
        "top_p: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with top_p=0.9)\n",
        "truncate: Truncates the input text until a given sequence, excluding that sequence (e.g. if truncate='<|endoftext|>', \n",
        "the returned text will include everything before the first <|endoftext|>). \n",
        "It may be useful to combine this with a smaller length if the input texts are short.\n",
        "include_prefix: If using truncate and include_prefix=False, the specified prefix will not be included in the returned text.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "j4l29QC_Wv-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.generate(sess, run_name='run1')"
      ],
      "metadata": {
        "id": "f0r5KF3YWm8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.generate(sess,\n",
        "              length=250,\n",
        "              temperature=0.7,\n",
        "              prefix=\"LORD\",\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "metadata": {
        "id": "30pyPyhDW0oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RulGPI4gW3RM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z_TPPFGnW3Tx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}