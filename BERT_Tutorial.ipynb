{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT_Tutorial",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNknVNZPRea+74w61cDgwvR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "95d439558b9440c1bff1e8e7a6a456c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e3c620a85f434ee9924e11c4283678e2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d29a6b3a2ef54481b7f0f28937900445",
              "IPY_MODEL_5e7514b287e5470ca495e49358a68a5a"
            ]
          }
        },
        "e3c620a85f434ee9924e11c4283678e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d29a6b3a2ef54481b7f0f28937900445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_26c13ad5b6834e0fa0a6155d77a71942",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_baef67e8c4a84325b3a6422775565939"
          }
        },
        "5e7514b287e5470ca495e49358a68a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bfcee18e5e9e4f90ba76cc295fa2d90d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 930kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_97ff0e523a0f43b690eac3612106ce1e"
          }
        },
        "26c13ad5b6834e0fa0a6155d77a71942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "baef67e8c4a84325b3a6422775565939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bfcee18e5e9e4f90ba76cc295fa2d90d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "97ff0e523a0f43b690eac3612106ce1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65581e7612484ea8a267fe4ef1f7c671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c0b8cd09c20c48dd97d85d5b214ad1a5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_95bd772c06cd4367922c11fa34b4d52b",
              "IPY_MODEL_15c17886c76c4783b598db1acb558b8f"
            ]
          }
        },
        "c0b8cd09c20c48dd97d85d5b214ad1a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95bd772c06cd4367922c11fa34b4d52b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_149e992a458b480a861fa9f5c086d4e4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_746f64e564f84186806dcc0aca36a02d"
          }
        },
        "15c17886c76c4783b598db1acb558b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_be7b0feb0661431798c031fd4801b4b8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 2.98kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27ed7458077c4b1d83a5e62bd4e3df6e"
          }
        },
        "149e992a458b480a861fa9f5c086d4e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "746f64e564f84186806dcc0aca36a02d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be7b0feb0661431798c031fd4801b4b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27ed7458077c4b1d83a5e62bd4e3df6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a285c2bce24425a8de46ebd0b829142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_23405893e800495db4da92f882baf7c0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_13f7fd1676c541e98f0a3fea98b2141e",
              "IPY_MODEL_0dd1a3b257ea4cb8847c8b70e08c0543"
            ]
          }
        },
        "23405893e800495db4da92f882baf7c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13f7fd1676c541e98f0a3fea98b2141e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_47d05dc5c61840198832d9ae845acb7f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2bb442050d84450cb09a1afa7d5fe6f9"
          }
        },
        "0dd1a3b257ea4cb8847c8b70e08c0543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_01f8b97563d64847befeee9d24199bd5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [06:21&lt;00:00, 1.15MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_495743c26f9244f5b1fb3fa48b689a73"
          }
        },
        "47d05dc5c61840198832d9ae845acb7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2bb442050d84450cb09a1afa7d5fe6f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01f8b97563d64847befeee9d24199bd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "495743c26f9244f5b1fb3fa48b689a73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ludwigwittgenstein2/Research/blob/master/BERT_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4tZzK4mqQLh",
        "outputId": "797d8610-14e7-4c0e-9e24-8c94fa876e2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#Get the GPU device name\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "#Device name\n",
        "if device_name == '/device:GPU:0':\n",
        "  print('Found GPU at:{}'.format(device_name))\n",
        "else:\n",
        "  raise SystemError('GPU device not found')\n",
        "  "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at:/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRHKdeq8Umkf",
        "outputId": "c965ee45-6b6c-480a-b2b1-cfb69dd88179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "  device = torch.device(\"cuda\")\n",
        "  print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "  print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "#If not....\n",
        "else: \n",
        "  print('No GPU available, using CPU instead.')\n",
        "  device = torch.device(\"cpu\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkKX_UGmVrEs",
        "outputId": "c24f46ae-9aaf-4f45-def9-6f49c92ab472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 24.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 31.9MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 35.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=a41065774dc97472efbbcabd8de4d8a593987dfacd56dd7cbde79a48b55fc030\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHBR7VauVzC6",
        "outputId": "eb1bc699-7e0f-4dde-b670-31e379536b92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=105bae504a2aa6b732896aab6d4bc525905af4ab8ddc40654c0065eb970a4ae4\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gku9AO74V524",
        "outputId": "b22f76d0-8ec1-49c1-ed64-06c1222fb559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import wget\n",
        "import os   \n",
        "\n",
        "print('Downloading dataset....')\n",
        "\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "  wget.download(url, './cola_public_1.1.zip')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IqEbnGG0ALJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKQRm57kZTIW",
        "outputId": "c7b3b1cb-2070-4337-c28a-632ffa99a6bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#unzip the file\n",
        "\n",
        "if not os.path.exists('./cola_public/'):\n",
        "  !unzip cola_public_1.1.zip\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exobBPiTZcqc",
        "outputId": "e2658a7a-b8ad-4b7f-fae5-0070876da64d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Load the dataset \n",
        "\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\",delimiter='\\t', header=None, names=['sentence_source','label','label_notes','sentence'])\n",
        "\n",
        "#Report \n",
        "\n",
        "print('Number of training sentences:{:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "df.sample(10)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences:8,551\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>973</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The writers could so believe the boy.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4145</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>You are the only person that I can rely on.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1799</th>\n",
              "      <td>r-67</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The socks are ready for you to put on.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2872</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The eggs mixed with the cream.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3045</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ellen told Helen a story.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2620</th>\n",
              "      <td>l-93</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Doug removed the scratches to nowhere.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8172</th>\n",
              "      <td>ad03</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Gilgamesh never flies dragons.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3564</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I doubt if you can help me in understanding this.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>They hit the ball.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>660</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>We have someone in the living room.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "973             bc01  ...              The writers could so believe the boy.\n",
              "4145            ks08  ...        You are the only person that I can rely on.\n",
              "1799            r-67  ...             The socks are ready for you to put on.\n",
              "2872            l-93  ...                     The eggs mixed with the cream.\n",
              "3045            l-93  ...                          Ellen told Helen a story.\n",
              "2620            l-93  ...             Doug removed the scratches to nowhere.\n",
              "8172            ad03  ...                     Gilgamesh never flies dragons.\n",
              "3564            ks08  ...  I doubt if you can help me in understanding this.\n",
              "320             bc01  ...                                 They hit the ball.\n",
              "660             bc01  ...                We have someone in the living room.\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2BOamhVazx4",
        "outputId": "1adacc0d-6acf-4899-db24-ff5e85ff0f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.loc[df.label==0].sample(5)[['sentence','label']]\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7353</th>\n",
              "      <td>John needed.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1151</th>\n",
              "      <td>We elected the man who he had brought with him...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4159</th>\n",
              "      <td>Fifteen years represent a long period of his l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156</th>\n",
              "      <td>I insist in seeing all the students who starte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>It is important for the more you to eat, the m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "7353                                       John needed.      0\n",
              "1151  We elected the man who he had brought with him...      0\n",
              "4159  Fifteen years represent a long period of his l...      0\n",
              "1156  I insist in seeing all the students who starte...      0\n",
              "145   It is important for the more you to eat, the m...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HYIgsVHbZQO"
      },
      "source": [
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JErzjG2Cbi5I",
        "outputId": "52cf6866-5617-4f92-e5b3-3bae6f06bfe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "95d439558b9440c1bff1e8e7a6a456c1",
            "e3c620a85f434ee9924e11c4283678e2",
            "d29a6b3a2ef54481b7f0f28937900445",
            "5e7514b287e5470ca495e49358a68a5a",
            "26c13ad5b6834e0fa0a6155d77a71942",
            "baef67e8c4a84325b3a6422775565939",
            "bfcee18e5e9e4f90ba76cc295fa2d90d",
            "97ff0e523a0f43b690eac3612106ce1e"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "#Load Bert Tokenizer\n",
        "\n",
        "print('Loading BERT tokenizer....')\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95d439558b9440c1bff1e8e7a6a456c1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP4riLH7bhB1",
        "outputId": "da9cd2d5-d58e-4108-bfd5-51c480fe8c4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print('Original', sentences[0])\n",
        "\n",
        "print('Tokenized:', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "print('Token IDs:', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized: ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs: [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL7uhAEDcLeY",
        "outputId": "6d439aa3-1caf-4e17-88b7-055c25feb22f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_len = 0\n",
        "#For every sentence\n",
        "\n",
        "for sent in sentences: \n",
        "  input_ids = tokenizer.encode(sent,add_special_tokens=True)\n",
        "  max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length:', max_len)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length: 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of4i-jxGd9Ub"
      },
      "source": [
        "#Tokenize all sentences\n",
        "input_ids = []\n",
        "attention_masks = []\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dqQGtuCDYhO",
        "outputId": "087ad134-674d-4670-9095-7752a8254be8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation=True,\n",
        "                   )\n",
        "    \n",
        "    encoded_dict = tokenizer.encode_plus(sent,truncation=True, add_special_tokens=True,max_length=64, pad_to_max_length=True, return_attention_mask=True, return_tensors='pt',)\n",
        "\n",
        "    #Add the encoded sentence to list\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    #Add attention mask\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "  \n",
        "\n",
        "    \n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OPkYqmC4o5v",
        "outputId": "015cc819-1bd0-4827-f7d4-1a3c684c7583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: tensor([[  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
            "          2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHFM17a_Do6s",
        "outputId": "421f38a6-4773-4573-ffa9-1e3edca08a72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_len = 0 \n",
        "\n",
        "for sent in sentences: \n",
        "  input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "  max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length:', max_len)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length: 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC3WCT1tg5zt",
        "outputId": "ff04f2ad-1964-424d-d6cf-f04a94290379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "#Time to do the real tokenizer\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences: \n",
        "  #First Step is to Tokenize\n",
        "  #Second is to Prepend with '[CLS]' to the start\n",
        "  #Third is to append with '[SEP]' token to the end\n",
        "  #Map tokens to their IDs\n",
        "  #Pad or truncate the sentence to 'max_length'\n",
        "  #Create attention masks for [PAD] tokens\n",
        "  encoded_dict = tokenizer.encode_plus(sent, add_special_tokens=True, truncation=True, max_length=64, pad_to_max_length=True, return_attention_mask=True,return_tensors='pt', )\n",
        "  input_ids.append(encoded_dict['input_ids'])\n",
        "  attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "#Print\n",
        "print('Original', sentences[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
            "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uZOo3wO4tPa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4Rh4lfphX6l",
        "outputId": "e3070e38-076f-4c76-cabf-1060f4ee15ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Divide the Training Set for 90% training and %10 validation\n",
        "\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "#Combine training input into TensorDataset \n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "#Calculate number of samples to include in each set\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size \n",
        "\n",
        "#Divide dataset by randomly selecting samples. \n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7,695 training samples\n",
            "  856 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKLx4v94fJVL"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), \n",
        "                              batch_size=batch_size)\n",
        "\n",
        "validation_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), \n",
        "                                   batch_size=batch_size)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfZJlp3Ex7wU",
        "outputId": "eb1be6ef-98ee-42c0-92e0-4b58233f6c27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "65581e7612484ea8a267fe4ef1f7c671",
            "c0b8cd09c20c48dd97d85d5b214ad1a5",
            "95bd772c06cd4367922c11fa34b4d52b",
            "15c17886c76c4783b598db1acb558b8f",
            "149e992a458b480a861fa9f5c086d4e4",
            "746f64e564f84186806dcc0aca36a02d",
            "be7b0feb0661431798c031fd4801b4b8",
            "27ed7458077c4b1d83a5e62bd4e3df6e",
            "9a285c2bce24425a8de46ebd0b829142",
            "23405893e800495db4da92f882baf7c0",
            "13f7fd1676c541e98f0a3fea98b2141e",
            "0dd1a3b257ea4cb8847c8b70e08c0543",
            "47d05dc5c61840198832d9ae845acb7f",
            "2bb442050d84450cb09a1afa7d5fe6f9",
            "01f8b97563d64847befeee9d24199bd5",
            "495743c26f9244f5b1fb3fa48b689a73"
          ]
        }
      },
      "source": [
        "#BERT for Sequence Classification\n",
        "\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
        "                                                      num_labels=2, \n",
        "                                                      output_attentions=False, \n",
        "                                                      output_hidden_states=False,)\n",
        "model.cuda()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65581e7612484ea8a267fe4ef1f7c671",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a285c2bce24425a8de46ebd0b829142",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AhtVyYSycOg",
        "outputId": "8cfa7ffd-a716-4630-c26b-81f11a969ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "params = list(model.named_parameters())\n",
        "\n",
        "print('BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "print('===Embedding layer===\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "  print(\"{:<55}{:>12}\".format(p[0],str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n====First Transformer====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "  print(\"{:<55}{:>12}\".format(p[0],str(tuple(p[1].size()))))\n",
        "print('\\n===Output Layer====\\n')\n",
        "for p in params[-4:]:\n",
        "  print(\"{:<55}{:>22}\".format(p[0],str(tuple(p[1].size()))))\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BERT model has 201 different named parameters.\n",
            "\n",
            "===Embedding layer===\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                 (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight               (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight               (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                             (768,)\n",
            "bert.embeddings.LayerNorm.bias                               (768,)\n",
            "\n",
            "====First Transformer====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight         (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias               (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight           (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                 (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight         (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias               (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight       (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias             (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias         (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight          (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                       (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                 (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                   (768,)\n",
            "\n",
            "===Output Layer====\n",
            "\n",
            "bert.pooler.dense.weight                                           (768, 768)\n",
            "bert.pooler.dense.bias                                                 (768,)\n",
            "classifier.weight                                                    (2, 768)\n",
            "classifier.bias                                                          (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkQKHY_B0xbw"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81PCWCSm1E9y",
        "outputId": "aaa58acf-0f65-4322-cd9d-6f5f2c2efffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "optimizer"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdamW (\n",
              "Parameter Group 0\n",
              "    betas: (0.9, 0.999)\n",
              "    correct_bias: True\n",
              "    eps: 1e-08\n",
              "    lr: 2e-05\n",
              "    weight_decay: 0.0\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swThAzg41Fz5"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 4\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0707zwsc1Xln"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LylaU-7D1Y2W"
      },
      "source": [
        "import time\n",
        "import datetime \n",
        "\n",
        "def format_time(elapsed):\n",
        "  elapsed_rounded = int(round((elapsed)))\n",
        "  return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWk0KaBD15Vh",
        "outputId": "3c0721a9-c8f4-429e-8bea-dcc858e04050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:00.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:15.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:29.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:01:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.91\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:45.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:00.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:15.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:30.\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Training epcoh took: 0:01:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.91\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:45.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:00.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:15.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:30.\n",
            "\n",
            "  Average training loss: 0.22\n",
            "  Training epcoh took: 0:01:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.91\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:45.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:00.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:15.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:30.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:01:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.91\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:06:15 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhKndQr26aIZ",
        "outputId": "dfb0b597-180f-4258-c698-d065abb66eff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#Summary of Progress\n",
        "import pandas as pd \n",
        "#Display flots with two decimal places\n",
        "pd.set_option('precision', 2)\n",
        "#Create a DataFrame from out training statistics \n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "#Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "#Display table\n",
        "df_stats\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:01:30</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:01:31</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.22</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:01:31</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.24</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:01:30</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.01         0.91           0.83       0:01:30         0:00:03\n",
              "2               0.21         0.91           0.83       0:01:31         0:00:03\n",
              "3               0.22         0.91           0.83       0:01:31         0:00:03\n",
              "4               0.24         0.91           0.83       0:01:30         0:00:03"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKPY5QeiChda",
        "outputId": "ba374589-8ea5-405d-a1e6-8b4d5dfd558e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plZNtXtpGd5i",
        "outputId": "c177b449-b58b-4367-e7e4-32369972e8c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation = True, \n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2C4aUtRJUJ3",
        "outputId": "bc8332a2-aed1-47ac-effc-38c76dbb9d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFNvDu0FKExt",
        "outputId": "ea788e44-768d-4edd-ef88-5c1ec41c103f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H-8TRtzKG2n",
        "outputId": "5294d0dc-718d-49ba-98fe-01c4e970e83b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_oymp4SKIb0",
        "outputId": "feefcf9c-8932-4e06-9993-0a682bc68281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHx2I368KKT6",
        "outputId": "97a73bfd-30f6-47d0-949c-dddf088907ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7fcoy-ZKMyz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}