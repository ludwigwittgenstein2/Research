{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOzIBt5ftYw/ClwxyZ6jn5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ludwigwittgenstein2/Research/blob/master/PDF_Text_Converter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUCVEuePbiK7",
        "outputId": "3f48df31-e890-4243-d1dc-ab0b50a127b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20250327 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20250327 pdfplumber-0.11.6 pypdfium2-4.30.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsduGzW7bJ9o",
        "outputId": "4468edf8-2d9c-425d-f3e5-30123f846502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JboxkOf3bAG1",
        "outputId": "ed75cf63-f08a-4143-c95e-94242f7ed353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To what extent do you feel...\n",
            "Not at all\n",
            "A little\n",
            "A moderate \n",
            "amount\n",
            "Quite a bit\n",
            "A lot\n",
            "Not at all\n",
            "A little\n",
            "A moderate \n",
            "amount\n",
            "Quite a bit\n",
            "A lot\n",
            "Your non-osteopathic faculty members and staff are supportive of osteopathic \n",
            "residency/fellowship education?\n",
            "0.0%\n",
            "1.4%\n",
            "6.9%\n",
            "29.2%\n",
            "62.5%\n",
            "0.6%\n",
            "2.5%\n",
            "10.0%\n",
            "27.4%\n",
            "59.6%\n",
            "Your osteopathic faculty members role model the integration of Osteopathic \n",
            "Principles and Practice?\n",
            "0.0%\n",
            "2.8%\n",
            "9.7%\n",
            "22.2%\n",
            "65.3%\n",
            "1.2%\n",
            "2.9%\n",
            "10.0%\n",
            "27.0%\n",
            "58.9%\n",
            "You are supervised by osteopathic faculty members?\n",
            "0.0%\n",
            "1.4%\n",
            "8.3%\n",
            "23.6%\n",
            "66.7%\n",
            "0.7%\n",
            "4.0%\n",
            "11.6%\n",
            "27.8%\n",
            "56.0%\n",
            "You are evaluated on Osteopathic Principles and Practices?\n",
            "0.0%\n",
            "2.8%\n",
            "12.5%\n",
            "22.2%\n",
            "62.5%\n",
            "2.5%\n",
            "6.7%\n",
            "14.8%\n",
            "27.6%\n",
            "48.3%\n",
            "Your program supports you to explore scholarly activity that integrates Osteopathic \n",
            "Principles and Practice?\n",
            "1.4%\n",
            "2.8%\n",
            "5.6%\n",
            "25.0%\n",
            "65.3%\n",
            "1.8%\n",
            "4.6%\n",
            "12.2%\n",
            "26.4%\n",
            "55.0%\n",
            "List of osteopathic recognized programs responding to this survey: (5 Program(s))\n",
            "Program Code\n",
            "Specialty Name\n",
            "0403800177\n",
            "Anesthesiology\n",
            "1203811238\n",
            "Family medicine\n",
            "1403800537\n",
            "Internal medicine\n",
            "2603800181\n",
            "Orthopaedic surgery\n",
            "4403800405\n",
            "Surgery\n",
            "Definitely \n",
            "not choose \n",
            "again\n",
            "Probably not \n",
            "choose \n",
            "again\n",
            "Might or \n",
            "might not \n",
            "choose \n",
            "again\n",
            "Probably \n",
            "choose \n",
            "again\n",
            "Definitely \n",
            "choose \n",
            "again\n",
            "Definitely \n",
            "not choose \n",
            "again\n",
            "Probably not \n",
            "choose \n",
            "again\n",
            "Might or \n",
            "might not \n",
            "choose \n",
            "again\n",
            "Probably \n",
            "choose \n",
            "again\n",
            "Definitely \n",
            "choose \n",
            "again\n",
            "Thinking specifically about the osteopathic education provided by this program, \n",
            "how likely would you be to choose to be a designated osteopathic resident in this \n",
            "program again?\n",
            "2.8%\n",
            "2.8%\n",
            "11.1%\n",
            "34.7%\n",
            "48.6%\n",
            "2.1%\n",
            "3.2%\n",
            "12.6%\n",
            "27.8%\n",
            "54.4%\n",
            "Strongly \n",
            "disagree\n",
            "Disagree\n",
            "Neutral\n",
            "Agree\n",
            "Strongly \n",
            "agree\n",
            "Strongly \n",
            "disagree\n",
            "Disagree\n",
            "Neutral\n",
            "Agree\n",
            "Strongly \n",
            "agree\n",
            "The osteopathic education provided by this program is preparing me to incorporate \n",
            "OPP in my future practice.\n",
            "1.4%\n",
            "0.0%\n",
            "13.9%\n",
            "40.3%\n",
            "44.4%\n",
            "1.4%\n",
            "2.9%\n",
            "14.8%\n",
            "33.3%\n",
            "47.5%\n",
            "Program\n",
            "National\n",
            "Hospital/Inpatient \n",
            "Setting\n",
            "Clinic/Outpatient \n",
            "Setting\n",
            "Didactic \n",
            "Setting\n",
            "Hospital/Inpatient \n",
            "Setting\n",
            "Clinic/Outpatient \n",
            "Setting\n",
            "Didactic \n",
            "Setting\n",
            "Yes\n",
            "No\n",
            "N/A\n",
            "Yes\n",
            "No\n",
            "N/A\n",
            "Yes\n",
            "No\n",
            "Yes\n",
            "No\n",
            "N/A\n",
            "Yes\n",
            "No\n",
            "N/A\n",
            "Yes\n",
            "No\n",
            "Do you receive an adequate education in Osteopathic Principles and Practices?\n",
            "95.8%\n",
            "4.2%\n",
            "0.0%\n",
            "88.9%\n",
            "1.4%\n",
            "9.7%\n",
            "98.6%\n",
            "1.4%\n",
            "74.2%\n",
            "16.6%\n",
            "9.1%\n",
            "90.9%\n",
            "3.7%\n",
            "5.4%\n",
            "96.2%\n",
            "3.8%\n",
            "Do you receive an adequate education in Osteopathic Manipulative Treatment, as \n",
            "applicable to your specialty/subspecialty?\n",
            "94.4%\n",
            "4.2%\n",
            "1.4%\n",
            "88.9%\n",
            "2.8%\n",
            "8.3%\n",
            "97.2%\n",
            "2.8%\n",
            "71.2%\n",
            "18.5%\n",
            "10.3%\n",
            "90.0%\n",
            "4.1%\n",
            "5.9%\n",
            "95.7%\n",
            "4.3%\n",
            "© 2024 Accreditation Council for Graduate Medical Education (ACGME)\n",
            "Percentages may not add to 100% due to rounding.\n",
            "2023-2024 ACGME Resident/Fellow Survey\n",
            "380393    Cleveland Clinic Foundation - Aggregated Program Data\n",
            "Residents Responded  72\n",
            "Survey taken: February 2024 - April 2024\n",
            "Osteopathic Recognition Survey Questions\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Create a PDF reader object\n",
        "reader = PdfReader(\"file_1.pdf\")\n",
        "\n",
        "# Extract text from the first page\n",
        "page = reader.pages[0]\n",
        "text = page.extract_text()\n",
        "print(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import pandas as pd\n",
        "\n",
        "# Open the PDF file\n",
        "with pdfplumber.open(\"file_1.pdf\") as pdf:\n",
        "    data = []\n",
        "    # Iterate through all pages\n",
        "    for page in pdf.pages:\n",
        "        text = page.extract_text()\n",
        "        if text:\n",
        "            # Split text into lines and append to data\n",
        "            lines = text.split('\\n')\n",
        "            data.extend(lines)\n",
        "\n",
        "    # Save extracted lines into a CSV file\n",
        "    df = pd.DataFrame(data, columns=[\"Text\"])\n",
        "    df.to_csv(\"file_1.csv\", index=False)\n",
        "\n",
        "print(\"PDF text has been saved to output.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQN3KPlqbYwo",
        "outputId": "291b0906-0739-4e96-a5bb-48b2bdbd3e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF text has been saved to output.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install camelot-py[cv]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMH6W1xtbFCm",
        "outputId": "9c933093-afdd-4d84-a80c-a4e3af7eebef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting camelot-py[cv]\n",
            "  Downloading camelot_py-1.0.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "\u001b[33mWARNING: camelot-py 1.0.0 does not provide the extra 'cv'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.11/dist-packages (from camelot-py[cv]) (8.1.8)\n",
            "Requirement already satisfied: chardet>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from camelot-py[cv]) (5.2.0)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from camelot-py[cv]) (2.0.2)\n",
            "Requirement already satisfied: openpyxl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from camelot-py[cv]) (3.1.5)\n",
            "Requirement already satisfied: pdfminer-six>=20240706 in /usr/local/lib/python3.11/dist-packages (from camelot-py[cv]) (20250327)\n",
            "Collecting pypdf<4.0,>=3.17 (from camelot-py[cv])\n",
            "  Downloading pypdf-3.17.4-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: pandas>=2.2.2 in /usr/local/lib/python3.11/dist-packages (from camelot-py[cv]) (2.2.2)\n",
            "Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from camelot-py[cv]) (0.9.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.7.0.68 in /usr/local/lib/python3.11/dist-packages (from camelot-py[cv]) (4.11.0.86)\n",
            "Requirement already satisfied: pypdfium2>=4 in /usr/local/lib/python3.11/dist-packages (from camelot-py[cv]) (4.30.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl>=3.1.0->camelot-py[cv]) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.2->camelot-py[cv]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.2->camelot-py[cv]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.2->camelot-py[cv]) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer-six>=20240706->camelot-py[cv]) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer-six>=20240706->camelot-py[cv]) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer-six>=20240706->camelot-py[cv]) (1.17.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.2->camelot-py[cv]) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20240706->camelot-py[cv]) (2.22)\n",
            "Downloading pypdf-3.17.4-py3-none-any.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading camelot_py-1.0.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf, camelot-py\n",
            "Successfully installed camelot-py-1.0.0 pypdf-3.17.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabula-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XZwihXdJO2K",
        "outputId": "7f209571-27c3-44e6-edfc-c960763b8c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tabula-py\n",
            "  Downloading tabula_py-2.10.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.11/dist-packages (from tabula-py) (2.2.2)\n",
            "Requirement already satisfied: numpy>1.24.4 in /usr/local/lib/python3.11/dist-packages (from tabula-py) (2.0.2)\n",
            "Requirement already satisfied: distro in /usr/local/lib/python3.11/dist-packages (from tabula-py) (1.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25.3->tabula-py) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25.3->tabula-py) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->tabula-py) (1.17.0)\n",
            "Downloading tabula_py-2.10.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/12.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/12.0 MB\u001b[0m \u001b[31m144.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m11.1/12.0 MB\u001b[0m \u001b[31m174.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m169.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tabula-py\n",
            "Successfully installed tabula-py-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import camelot\n",
        "import pandas as pd\n",
        "\n",
        "# Extract tables from the PDF (use 'lattice' for bordered tables or 'stream' otherwise)\n",
        "tables = camelot.read_pdf(\"file_1.pdf\", pages=\"all\", flavor=\"lattice\")\n",
        "\n",
        "# Check if tables were found\n",
        "if not tables:\n",
        "    print(\"No tables found in the PDF.\")\n",
        "else:\n",
        "    # Create an empty DataFrame to hold all table data\n",
        "    combined_df = pd.DataFrame()\n",
        "\n",
        "    # Iterate through extracted tables and append them to the DataFrame\n",
        "    for i, table in enumerate(tables):\n",
        "        df = table.df  # Convert table to a pandas DataFrame\n",
        "        combined_df = pd.concat([combined_df, df], ignore_index=True)  # Append to combined DataFrame\n",
        "\n",
        "    # Save the combined DataFrame to a single CSV file\n",
        "    combined_df.to_csv(\"test_1.csv\", index=False, header=False)\n",
        "\n",
        "    print(f\"All tables have been extracted and saved to test_1.csv.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO8Okc-bJR1D",
        "outputId": "271a7339-f490-4fec-d63c-a251c1ab401f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tables have been extracted and saved to test_1.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOCYd5SVMt7g",
        "outputId": "e757ecdc-5626-4ccf-b168-15bf83e38dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjMaMIrQM1Q2",
        "outputId": "7cb5b294-64af-46d3-e297-f0a8bb834741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.1.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!brew install poppler\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpY9mQqCNAq9",
        "outputId": "69a496d1-d197-4461-af6b-47a983b5c19b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: brew: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary dependencies\n",
        "!apt-get install -y poppler-utils  # Install Poppler for pdf2image\n",
        "!pip install pdf2image pytesseract pillow  # Install required Python libraries\n",
        "\n",
        "import csv\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "\n",
        "# Convert PDF pages to images\n",
        "pdf_path = \"/content/file_1.pdf\"  # Path to your PDF file (upload it to Colab)\n",
        "pages = convert_from_path(pdf_path)\n",
        "\n",
        "# Open a CSV file to save extracted data\n",
        "output_csv = \"/content/output.csv\"  # Path to save the output CSV file\n",
        "with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "\n",
        "    # Process each page image with Tesseract OCR\n",
        "    for page_num, page_image in enumerate(pages):\n",
        "        text = pytesseract.image_to_string(page_image)\n",
        "\n",
        "        # Split text into lines and write each line as a row in the CSV file\n",
        "        lines = text.split(\"\\n\")\n",
        "        for line in lines:\n",
        "            writer.writerow([line])\n",
        "\n",
        "print(f\"Scanned PDF content has been saved to {output_csv}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFlOIMxPMuWb",
        "outputId": "751def03-421b-4058-c916-4e7bca33002f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 30 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.7 [186 kB]\n",
            "Fetched 186 kB in 1s (371 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126315 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.7_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.7) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.7) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Scanned PDF content has been saved to /content/output.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "\n",
        "# Convert PDF pages to images\n",
        "pages = convert_from_path(\"/content/file_1.pdf\")\n",
        "\n",
        "# Extract structured text using Tesseract OCR\n",
        "output_text_path = \"/content/output.txt\"\n",
        "with open(output_text_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
        "    for page_image in pages:\n",
        "        text = pytesseract.image_to_string(page_image, config=\"--psm 6\")  # Preserve layout with PSM mode 6\n",
        "        txt_file.write(text + \"\\n\")\n",
        "\n",
        "print(f\"OCR-extracted text has been saved to {output_text_path}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w11JRs1VOK0Q",
        "outputId": "48c268f8-11fc-43e8-fb65-bbf7e9bd0e78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OCR-extracted text has been saved to /content/output.txt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import pdfplumber\n",
        "from tabula import convert_into\n",
        "import camelot\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "\n",
        "def extract_with_tabula(input_pdf, output_csv):\n",
        "    \"\"\"\n",
        "    Extract tables using Tabula and save them to a CSV file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        convert_into(input_pdf, output_csv, output_format=\"csv\", pages=\"all\", lattice=True)\n",
        "        print(f\"Tables extracted using Tabula and saved to {output_csv}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Tabula extraction failed: {e}\")\n",
        "\n",
        "def extract_with_camelot(input_pdf, output_csv):\n",
        "    \"\"\"\n",
        "    Extract tables using Camelot and save them to a CSV file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        tables = camelot.read_pdf(input_pdf, pages=\"all\", flavor=\"lattice\")\n",
        "        if tables:\n",
        "            for i, table in enumerate(tables):\n",
        "                table.to_csv(f\"{os.path.splitext(output_csv)[0]}_table_{i + 1}.csv\")\n",
        "                print(f\"Table {i + 1} saved as {os.path.splitext(output_csv)[0]}_table_{i + 1}.csv\")\n",
        "        else:\n",
        "            print(\"No tables found with Camelot.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Camelot extraction failed: {e}\")\n",
        "\n",
        "def extract_with_pdfplumber(input_pdf, output_csv):\n",
        "    \"\"\"\n",
        "    Extract text-based tables using pdfplumber and save them to a CSV file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with pdfplumber.open(input_pdf) as pdf:\n",
        "            with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "                writer = csv.writer(csvfile)\n",
        "                for page in pdf.pages:\n",
        "                    table = page.extract_table()\n",
        "                    if table:\n",
        "                        writer.writerows(table)\n",
        "        print(f\"Tables extracted using pdfplumber and saved to {output_csv}\")\n",
        "    except Exception as e:\n",
        "        print(f\"pdfplumber extraction failed: {e}\")\n",
        "\n",
        "def extract_with_tesseract(input_pdf, output_csv):\n",
        "    \"\"\"\n",
        "    Perform OCR on scanned PDFs using Tesseract and save the extracted text to a CSV file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        pages = convert_from_path(input_pdf)\n",
        "        with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "            writer = csv.writer(csvfile)\n",
        "            for page_num, page_image in enumerate(pages):\n",
        "                text = pytesseract.image_to_string(page_image)\n",
        "                lines = text.split(\"\\n\")\n",
        "                for line in lines:\n",
        "                    writer.writerow([line])\n",
        "        print(f\"OCR extraction using Tesseract completed and saved to {output_csv}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Tesseract OCR extraction failed: {e}\")\n",
        "\n",
        "def main():\n",
        "    input_pdf = \"file_1.pdf\"  # Input PDF file\n",
        "    output_csv = \"test_1.csv\"  # Output CSV file\n",
        "\n",
        "    print(\"Starting PDF extraction...\")\n",
        "\n",
        "    # Step 1: Try extracting with Tabula (best for structured tables)\n",
        "    extract_with_tabula(input_pdf, output_csv)\n",
        "\n",
        "    # Step 2: If Tabula fails or additional extraction is needed, try Camelot\n",
        "    extract_with_camelot(input_pdf, output_csv)\n",
        "\n",
        "    # Step 3: For unstructured text-based tables, use pdfplumber\n",
        "    extract_with_pdfplumber(input_pdf, output_csv)\n",
        "\n",
        "    # Step 4: If the PDF is scanned (images), perform OCR using Tesseract\n",
        "    extract_with_tesseract(input_pdf, output_csv)\n",
        "\n",
        "    print(\"PDF extraction process completed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wupvDoGxSIPL",
        "outputId": "337721e2-b2a7-4dcf-a33a-e1f0d6a5b7a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tabula.backend:Failed to import jpype dependencies. Fallback to subprocess.\n",
            "WARNING:tabula.backend:No module named 'jpype'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting PDF extraction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tabula.backend:Got stderr: Apr 11, 2025 7:17:02 PM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider loadDiskCache\n",
            "WARNING: New fonts found, font cache will be re-built\n",
            "Apr 11, 2025 7:17:02 PM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider <init>\n",
            "WARNING: Building on-disk font cache, this may take a while\n",
            "Apr 11, 2025 7:17:02 PM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider <init>\n",
            "WARNING: Finished building on-disk font cache, found 17 fonts\n",
            "Apr 11, 2025 7:17:03 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Apr 11, 2025 7:17:03 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tables extracted using Tabula and saved to test_1.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table 1 saved as test_1_table_1.csv\n",
            "Table 2 saved as test_1_table_2.csv\n",
            "Table 3 saved as test_1_table_3.csv\n",
            "Table 4 saved as test_1_table_4.csv\n",
            "Table 5 saved as test_1_table_5.csv\n",
            "Table 6 saved as test_1_table_6.csv\n",
            "Table 7 saved as test_1_table_7.csv\n",
            "Table 8 saved as test_1_table_8.csv\n",
            "Table 9 saved as test_1_table_9.csv\n",
            "Table 10 saved as test_1_table_10.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tables extracted using pdfplumber and saved to test_1.csv\n",
            "OCR extraction using Tesseract completed and saved to test_1.csv\n",
            "PDF extraction process completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fitz"
      ],
      "metadata": {
        "id": "kIGQRzaPTs9V",
        "outputId": "1c1a5aa4-d325-4204-b37c-97ae3ac8f3d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fitz\n",
            "  Downloading fitz-0.0.1.dev2-py2.py3-none-any.whl.metadata (816 bytes)\n",
            "Collecting configobj (from fitz)\n",
            "  Downloading configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting configparser (from fitz)\n",
            "  Downloading configparser-7.2.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.11/dist-packages (from fitz) (0.22.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from fitz) (5.3.2)\n",
            "Collecting nipype (from fitz)\n",
            "  Downloading nipype-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fitz) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from fitz) (2.2.2)\n",
            "Collecting pyxnat (from fitz)\n",
            "  Downloading pyxnat-1.6.3-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from fitz) (1.14.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2->fitz) (3.2.3)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->fitz) (6.5.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel->fitz) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel->fitz) (4.13.1)\n",
            "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (8.1.8)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (3.4.2)\n",
            "Collecting prov>=1.5.2 (from nipype->fitz)\n",
            "  Downloading prov-2.0.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (2.8.2)\n",
            "Collecting rdflib>=5.0.0 (from nipype->fitz)\n",
            "  Downloading rdflib-7.1.4-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: simplejson>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (3.20.1)\n",
            "Collecting traits>=6.2 (from nipype->fitz)\n",
            "  Downloading traits-7.0.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (3.18.0)\n",
            "Collecting acres (from nipype->fitz)\n",
            "  Downloading acres-0.3.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting etelemetry>=0.3.1 (from nipype->fitz)\n",
            "  Downloading etelemetry-0.3.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting looseversion!=1.2 (from nipype->fitz)\n",
            "  Downloading looseversion-1.3.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting puremagic (from nipype->fitz)\n",
            "  Downloading puremagic-1.28-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->fitz) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->fitz) (2025.2)\n",
            "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.11/dist-packages (from pyxnat->fitz) (5.3.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from pyxnat->fitz) (2.32.3)\n",
            "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.11/dist-packages (from pyxnat->fitz) (1.0.1)\n",
            "Collecting ci-info>=0.2 (from etelemetry>=0.3.1->nipype->fitz)\n",
            "  Downloading ci_info-0.3.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting rdflib>=5.0.0 (from nipype->fitz)\n",
            "  Downloading rdflib-6.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.2->nipype->fitz) (1.17.0)\n",
            "Collecting isodate<0.7.0,>=0.6.0 (from rdflib>=5.0.0->nipype->fitz)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->pyxnat->fitz) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->pyxnat->fitz) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->pyxnat->fitz) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->pyxnat->fitz) (2025.1.31)\n",
            "Downloading fitz-0.0.1.dev2-py2.py3-none-any.whl (20 kB)\n",
            "Downloading configobj-5.0.9-py2.py3-none-any.whl (35 kB)\n",
            "Downloading configparser-7.2.0-py3-none-any.whl (17 kB)\n",
            "Downloading nipype-1.10.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyxnat-1.6.3-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.4/95.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading etelemetry-0.3.1-py3-none-any.whl (6.4 kB)\n",
            "Downloading looseversion-1.3.0-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading prov-2.0.1-py3-none-any.whl (421 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.1/528.1 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading traits-7.0.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading acres-0.3.0-py3-none-any.whl (10 kB)\n",
            "Downloading puremagic-1.28-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ci_info-0.3.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: puremagic, looseversion, traits, isodate, configparser, configobj, ci-info, acres, rdflib, pyxnat, etelemetry, prov, nipype, fitz\n",
            "Successfully installed acres-0.3.0 ci-info-0.3.0 configobj-5.0.9 configparser-7.2.0 etelemetry-0.3.1 fitz-0.0.1.dev2 isodate-0.6.1 looseversion-1.3.0 nipype-1.10.0 prov-2.0.1 puremagic-1.28 pyxnat-1.6.3 rdflib-6.3.2 traits-7.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7dCKznGW9Fz",
        "outputId": "7762de53-0d4a-4715-dc94-ef891e979557"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Different files"
      ],
      "metadata": {
        "id": "iAq_9wFiVept"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import fitz  # PyMuPDF\n",
        "import pdfplumber\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "\n",
        "# Paths for input and output files\n",
        "pdf_path = \"/content/file_1.pdf\"  # Input PDF file\n",
        "\n",
        "# Step 1: Extract text using pdftotext (Poppler)\n",
        "try:\n",
        "    print(\"Extracting text using pdftotext...\")\n",
        "    pdftotext_output_path = \"/content/pdftotext_output.txt\"\n",
        "    subprocess.run([\"pdftotext\", \"-layout\", pdf_path, pdftotext_output_path])\n",
        "    print(f\"Text extracted using pdftotext and saved to {pdftotext_output_path}.\")\n",
        "except Exception as e:\n",
        "    print(f\"pdftotext extraction failed: {e}\")\n",
        "\n",
        "# Step 2: Extract text using PyMuPDF (fitz)\n",
        "try:\n",
        "    print(\"Extracting text using PyMuPDF...\")\n",
        "    pymupdf_output_path = \"/content/pymupdf_output.txt\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    with open(pymupdf_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for page_num in range(len(doc)):\n",
        "            page = doc[page_num]\n",
        "            text = page.get_text(\"text\")  # Preserve layout as plain text\n",
        "            f.write(text + \"\\n\")\n",
        "    print(f\"Text extracted using PyMuPDF and saved to {pymupdf_output_path}.\")\n",
        "except Exception as e:\n",
        "    print(f\"PyMuPDF extraction failed: {e}\")\n",
        "\n",
        "# Step 3: Extract text using pdfplumber\n",
        "try:\n",
        "    print(\"Extracting text using pdfplumber...\")\n",
        "    pdfplumber_output_path = \"/content/pdfplumber_output.txt\"\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        with open(pdfplumber_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            for page in pdf.pages:\n",
        "                text = page.extract_text()\n",
        "                if text:\n",
        "                    f.write(text + \"\\n\")\n",
        "    print(f\"Text extracted using pdfplumber and saved to {pdfplumber_output_path}.\")\n",
        "except Exception as e:\n",
        "    print(f\"pdfplumber extraction failed: {e}\")\n",
        "\n",
        "# Step 4: Extract text using Tesseract OCR (for scanned PDFs)\n",
        "try:\n",
        "    print(\"Performing OCR extraction using Tesseract...\")\n",
        "    ocr_output_path = \"/content/ocr_output.txt\"\n",
        "    pages = convert_from_path(pdf_path)\n",
        "    with open(ocr_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for page_image in pages:\n",
        "            text = pytesseract.image_to_string(page_image, config=\"--psm 6\")  # Preserve layout with PSM mode 6\n",
        "            f.write(text + \"\\n\")\n",
        "    print(f\"OCR extraction completed and saved to {ocr_output_path}.\")\n",
        "except Exception as e:\n",
        "    print(f\"Tesseract OCR extraction failed: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9M9DEM4VgIW",
        "outputId": "1703c825-873e-4344-af84-8b4451d6d75e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting text using pdftotext...\n",
            "Text extracted using pdftotext and saved to /content/pdftotext_output.txt.\n",
            "Extracting text using PyMuPDF...\n",
            "Text extracted using PyMuPDF and saved to /content/pymupdf_output.txt.\n",
            "Extracting text using pdfplumber...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text extracted using pdfplumber and saved to /content/pdfplumber_output.txt.\n",
            "Performing OCR extraction using Tesseract...\n",
            "OCR extraction completed and saved to /content/ocr_output.txt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9or_VSzCYHAP",
        "outputId": "c1dfb172-6f71-4ca7-fcdc-dfa1e05f56fa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.21.0+cu124)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from easyocr) (4.11.0.86)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.14.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from easyocr) (11.1.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.25.2)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.1.0)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->easyocr)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->easyocr)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->easyocr)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->easyocr)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->easyocr)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->easyocr)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->easyocr) (1.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2025.3.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->easyocr) (3.0.2)\n",
            "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.9/292.9 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, easyocr\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed easyocr-1.7.2 ninja-1.11.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyclipper-1.3.0.post6 python-bidi-0.6.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "import easyocr\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "# Paths for input and output files\n",
        "pdf_path = \"/content/file_1.pdf\"  # Input PDF file\n",
        "output_csv_path = \"/content/easyOCR_file_1.csv\"  # Output CSV file\n",
        "\n",
        "# Step 1: Convert PDF pages to images\n",
        "print(\"Converting PDF pages to images...\")\n",
        "pages = convert_from_path(pdf_path)\n",
        "print(f\"Converted {len(pages)} pages into images.\")\n",
        "\n",
        "# Step 2: Initialize EasyOCR reader\n",
        "print(\"Initializing EasyOCR...\")\n",
        "reader = easyocr.Reader(['en'], gpu=False)  # Use GPU=True if available for faster processing\n",
        "\n",
        "# Step 3: Extract text from each page image using EasyOCR\n",
        "print(\"Extracting text using EasyOCR...\")\n",
        "all_text = []  # List to store extracted text from all pages\n",
        "\n",
        "for page_num, page_image in enumerate(pages):\n",
        "    print(f\"Processing page {page_num + 1}...\")\n",
        "    # Convert Pillow image to NumPy array\n",
        "    page_array = np.array(page_image)\n",
        "    # Use EasyOCR to extract text\n",
        "    result = reader.readtext(page_array, detail=0)  # Extract text without bounding boxes or confidence scores\n",
        "    all_text.append(result)\n",
        "\n",
        "# Step 4: Save extracted text to a CSV file\n",
        "print(\"Saving extracted text to CSV...\")\n",
        "with open(output_csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    for page_num, page_text in enumerate(all_text):\n",
        "        writer.writerow([f\"Page {page_num + 1}\"])  # Add page number as header\n",
        "        for line in page_text:\n",
        "            writer.writerow([line])  # Write each line of text as a row\n",
        "\n",
        "print(f\"Text extracted using EasyOCR has been saved to {output_csv_path}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c40S7VRYFfo",
        "outputId": "c6fa39f4-c43e-4b2d-906b-5dc516d43fef"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting PDF pages to images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Using CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 1 pages into images.\n",
            "Initializing EasyOCR...\n",
            "Extracting text using EasyOCR...\n",
            "Processing page 1...\n",
            "Saving extracted text to CSV...\n",
            "Text extracted using EasyOCR has been saved to /content/easyOCR_file_1.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "import easyocr\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "# Paths for input and output files\n",
        "pdf_path = \"/content/file_1.pdf\"  # Input PDF file\n",
        "output_csv_path = \"/content/easyOCR_file_2.csv\"  # Output CSV file\n",
        "\n",
        "# Step 1: Convert PDF pages to images\n",
        "print(\"Converting PDF pages to images...\")\n",
        "pages = convert_from_path(pdf_path)\n",
        "print(f\"Converted {len(pages)} pages into images.\")\n",
        "\n",
        "# Step 2: Initialize EasyOCR reader\n",
        "print(\"Initializing EasyOCR...\")\n",
        "reader = easyocr.Reader(['en'], gpu=False)  # Use GPU=True if available for faster processing\n",
        "\n",
        "# Step 3: Extract text from each page image using EasyOCR\n",
        "print(\"Extracting text using EasyOCR...\")\n",
        "all_text = []  # List to store extracted text from all pages\n",
        "\n",
        "for page_num, page_image in enumerate(pages):\n",
        "    print(f\"Processing page {page_num + 1}...\")\n",
        "    # Convert Pillow image to NumPy array\n",
        "    page_array = np.array(page_image)\n",
        "    # Use EasyOCR to extract text with bounding boxes and confidence scores\n",
        "    results = reader.readtext(page_array)\n",
        "\n",
        "    # Group lines into paragraphs based on bounding box positions\n",
        "    page_text = []\n",
        "    for result in results:\n",
        "        _, text, _ = result  # Ignore bounding box and confidence score\n",
        "        page_text.append(text)\n",
        "\n",
        "    all_text.append(\"\\n\".join(page_text))  # Combine lines into paragraphs\n",
        "\n",
        "# Step 4: Save extracted text to a CSV file\n",
        "print(\"Saving extracted text to CSV...\")\n",
        "with open(output_csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    for page_num, page_text in enumerate(all_text):\n",
        "        writer.writerow([f\"Page {page_num + 1}\"])  # Add page number as header\n",
        "        writer.writerow([page_text])  # Write entire paragraph as a single row\n",
        "\n",
        "print(f\"Text extracted using EasyOCR has been saved to {output_csv_path}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF_VsrBMhlUi",
        "outputId": "6d7057b3-aa6c-4e5c-a6c7-de99e4fa8202"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Using CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting PDF pages to images...\n",
            "Converted 1 pages into images.\n",
            "Initializing EasyOCR...\n",
            "Extracting text using EasyOCR...\n",
            "Processing page 1...\n",
            "Saving extracted text to CSV...\n",
            "Text extracted using EasyOCR has been saved to /content/easyOCR_file_2.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xyjxmn9rkraE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "\n",
        "# Input and output file paths\n",
        "pdf_path = \"/content/file_1.pdf\"  # Input PDF file\n",
        "pymupdf_output_path = \"/content/pymupdf_output.txt\"  # Output text file\n",
        "\n",
        "# Extract text using PyMuPDF\n",
        "try:\n",
        "    print(\"Extracting text using PyMuPDF...\")\n",
        "    doc = fitz.open(pdf_path)\n",
        "    with open(pymupdf_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for page_num in range(len(doc)):\n",
        "            page = doc[page_num]\n",
        "            text = page.get_text(\"text\")  # Extract text while preserving layout\n",
        "            f.write(f\"Page {page_num + 1}\\n{text}\\n\")\n",
        "    print(f\"Text extracted using PyMuPDF and saved to {pymupdf_output_path}.\")\n",
        "except Exception as e:\n",
        "    print(f\"PyMuPDF extraction failed: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LouZZ6HYkr68",
        "outputId": "ab4c68ec-9f7a-42c8-a3ca-5c61268edc8a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting text using PyMuPDF...\n",
            "Text extracted using PyMuPDF and saved to /content/pymupdf_output.txt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IT05C_E-lOt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import csv\n",
        "\n",
        "# Input and output file paths\n",
        "pdf_path = \"/content/file_1.pdf\"  # Input PDF file\n",
        "pdftotext_output_path = \"/content/pdftotext_output2.txt\"  # Output text file\n",
        "pdftotext_csv_path = \"/content/pdftotext_output2.csv\"  # Output CSV file\n",
        "\n",
        "# Step 1: Extract text using pdftotext with the -layout option\n",
        "try:\n",
        "    print(\"Extracting text with table formatting using pdftotext...\")\n",
        "    subprocess.run([\"pdftotext\", \"-layout\", pdf_path, pdftotext_output_path])\n",
        "    print(f\"Text with table formatting extracted and saved to {pdftotext_output_path}.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during pdftotext extraction: {e}\")\n",
        "\n",
        "# Step 2: Convert extracted text to CSV format\n",
        "try:\n",
        "    print(\"Converting extracted text to CSV...\")\n",
        "    with open(pdftotext_output_path, \"r\", encoding=\"utf-8\") as txt_file:\n",
        "        lines = txt_file.readlines()\n",
        "\n",
        "    # Write lines to a CSV file\n",
        "    with open(pdftotext_csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        for line in lines:\n",
        "            writer.writerow([line.strip()])  # Write each line as a single row\n",
        "\n",
        "    print(f\"Extracted text has been converted to CSV and saved to {pdftotext_csv_path}.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during CSV conversion: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9uVtuL9lOwP",
        "outputId": "d832deb1-98a4-4224-b01f-ac7ab6aadf89"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting text with table formatting using pdftotext...\n",
            "Text with table formatting extracted and saved to /content/pdftotext_output2.txt.\n",
            "Converting extracted text to CSV...\n",
            "Extracted text has been converted to CSV and saved to /content/pdftotext_output2.csv.\n"
          ]
        }
      ]
    }
  ]
}