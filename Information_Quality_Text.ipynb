{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ludwigwittgenstein2/Research/blob/master/Information_Quality_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Information Quality of Text\n",
        "\n",
        "Dimensions:\n",
        "\n",
        "1. Relevance\n",
        "2. Consistency\n",
        "3. Accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "2wWoTcKE-gsF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gpt-2 Text Generator\n"
      ],
      "metadata": {
        "id": "-6voorBx-r7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "deIZHpnJ-tt8",
        "outputId": "158ce0a8-dfae-4019-b438-0ff4209f544b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y36pAWw-vQH",
        "outputId": "88878529-fbc7-4f28-ec1c-fed38be0b4da"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "124M (default): the \"small\" model, 500MB on disk.\n",
        "\n",
        "355M: the \"medium\" model, 1.5GB on disk.\n",
        "\n",
        "774M: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "\n",
        "1558M: the \"extra large\", true model. Will not work if a K80 GPU is attached to the notebook. (like 774M, it cannot be finetuned).\n"
      ],
      "metadata": {
        "id": "rintaMol-4Dt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9CrvpVc-aN4",
        "outputId": "c356bd33-cd22-4ec5-842a-4529f12fd36a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 1.86Git/s]                                                     \n",
            "Fetching encoder.json: 1.05Mit [00:00, 4.03Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 2.85Git/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:10, 47.8Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 1.08Git/s]                                               \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 5.69Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 4.91Mit/s]\n"
          ]
        }
      ],
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0fxnmdj_CQC",
        "outputId": "86239e3d-e52e-4b69-8efc-3a0dc270e48c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"CleanedDatasetEntire1.txt\""
      ],
      "metadata": {
        "id": "WGlOcknf_EBT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "metadata": {
        "id": "jk1DXkXC_IsR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "wBAdpIMn7J25"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f8xO7b8i7e7H",
        "outputId": "56932d0c-c636-4178-e338-82d286b5cff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-2ae153fb183f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_tf_sess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m gpt2.finetune(sess,\n\u001b[1;32m      4\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'reset_default_graph'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=10,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500,\n",
        "              reuse=None,\n",
        "              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MejE25A_KJg",
        "outputId": "8e68e714-4d3c-43cf-a19c-f32d990e0e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 2866.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 17233 tokens\n",
            "Training...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "metadata": {
        "id": "3NKKgBjZ_LhQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wlSMsN8I_M99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.reset_default_graph()"
      ],
      "metadata": {
        "id": "2vIS-N2N_NBH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "0X0QKsWB_PxZ",
        "outputId": "a121da24-8b9f-476b-d29e-828ae3b53ba8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint None\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-42fe8a91f36d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_tf_sess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_gpt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'run1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mload_gpt2\u001b[0;34m(sess, checkpoint, run_name, checkpoint_dir, model_name, model_dir, multi_gpu, reuse)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading checkpoint'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1404\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't load save_path when it is None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m     \u001b[0mcheckpoint_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Can't load save_path when it is None."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.generate(sess, run_name='run1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2LkUKXF_RBF",
        "outputId": "6c7243c1-b9cc-4ff7-d6c0-e5090d342b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, the crime scene is open as of 9:30 p.m. CT.\n",
            "\n",
            "Anyone with information regarding the crime is asked to contact Detective Brian Tucker at (408) 226-3871.\n",
            "\n",
            "The investigation remains ongoing.\n",
            "\n",
            "Contact:\n",
            "\n",
            "Rotham Miller\n",
            "\n",
            "community@games.com\n",
            "\n",
            "(408) 863-8070\n",
            "\n",
            "ajohnson@games.com<|endoftext|>The new Jurassic Park series is set for release on June 5, 2015, Disney said today.\n",
            "\n",
            "The series was created by Fox, Disney's studio behind the animated series.\n",
            "\n",
            "The series, which will premiere on January 12, 2015, is set to premiere on Disney XD starting June 5.\n",
            "\n",
            "\"Enjoy the action as Duke and Duke Rees face off against legendary foes in the first installment of the franchise,\" said Disney on its website. \"With the complete series, we're setting up a strong foundation for an epic story that will help shape the future of Disney's beloved franchises.\"\n",
            "\n",
            "The series will also premiere on Disney XD starting June 5, 2015.\n",
            "\n",
            "\"A new brand-new story about a mysterious character who learns about the world outside the park,\" said Fox. \"This new series explores the history of the park and will be a fresh take on the series.\"\n",
            "\n",
            "\"We're thrilled to bring Jurassic Park to Disney XD with a sequel,\" said Fox. \"Just as we love to see the park evolve, so too will we. The fans will love the new series and we're excited to bring it to their hearts.\"\n",
            "\n",
            "\"Jurassic World\" will premiere on Disney XD beginning March 6, 2015, and will premiere on Disney XD beginning June 12, 2015,\" ABC said. \"It's a big deal for fans, and we look forward to working with fans on exciting new stories.\"\n",
            "\n",
            "The first installment of the franchise will open in theaters on June 5, 2015.\n",
            "\n",
            "\"We're excited to bring Jurassic Park to Walt Disney Studios,\" said Amie Parnell, co-president and general manager of Disney XD. \"Through the best experiences, we're bringing together fans of all ages and backgrounds with stories from the park's past and present to create a story that will tell the story of the park and its future.\"\n",
            "\n",
            "\"The two-part series is set to premiere in theaters at 7 p.m. ET on March 6, 2015,\" said Disney on its website. \"It's a big deal for fans, and we look forward to working with fans on exciting new stories.\"\n",
            "\n",
            "\"Now, it's time for us to come together as one,\" said Jeanine O'Hara, senior vice president and general manager of content for Disney XD. \"We want to bring these two great stories together to create a bold new story that will show the world that we're all cool with each other.\"\n",
            "\n",
            "\"It's too early to tell what the future holds,\" said Mark Ruffalo, president and CEO of Disney XD. \"We're just beginning to get the details right.\"\n",
            "\n",
            "\"Jurassic 3\" will premiere on Disney XD starting April 16, 2015, and will premiere on Disney XD beginning March 6, 2015,\" ABC said. \"It's a big deal for fans, and we look forward to working with fans on exciting new stories.\"\n",
            "\n",
            "\"The first installment of the franchise will open in theaters on July 4, 2015,\" said Tegan Gage, executive producer of \"The Amazing Spider-Man 2,\" on Disney XD. \"It's a big deal for fans, and we look forward to working with fans on exciting new stories.\"\n",
            "\n",
            "\"We've taken a lot of steps to make this a successful franchise,\" said Laura Dern, senior vice president of content at Walt Disney Studios. \"We've worked hard to make sure that the story is a hit, and we're excited to see what happens on the big screen.\"\n",
            "\n",
            "\"We're excited to bring the first installment of the franchise to Disney XD,\" said Benito Floro, director of \"The Amazing Spider-Man 2,\" on Disney XD. \"It's a big deal for fans, and we look forward to working with fans on exciting new stories.\"\n",
            "\n",
            "\"We're excited to bring the first installment of the franchise to Disney XD,\" said Evan Goldberg, executive producer of \"The Amazing Spider-Man 2,\" on Disney XD. \"It's a big deal for fans, and we look forward to working with fans on exciting new stories.\"\n",
            "\n",
            "\"We're excited to bring the first installment of the franchise to Disney XD,\" said Mike Deodato, executive producer of \"The Amazing Spider-Man: Homecoming,\" on Disney XD. \"It's a big deal for fans, and we look forward to working with fans on exciting new stories.\"\n",
            "\n",
            "\"We're excited to bring the first installment of the franchise to Disney XD,\" said Arndt Cunha, senior producer and senior producer on \"The Amazing Spider\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.generate(sess,\n",
        "              length=250,\n",
        "              temperature=0.7,\n",
        "              prefix=\"LORD\",\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "metadata": {
        "id": "6faxcNPt_Scv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=500,\n",
        "                      temperature=0.7,\n",
        "                      nsamples=100,\n",
        "                      batch_size=20\n",
        "                      )"
      ],
      "metadata": {
        "id": "SXqUNVEQ_Ue9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "single_text = gpt2.generate(sess, return_as_list=True)\n",
        "print((single_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWIC7Myq_V2_",
        "outputId": "c8f7b659-854e-4411-96bf-62380eb09fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A former home secretary who fled London for Syria pleaded guilty to conspiring to supply arms and intelligence to Islamic State extremists in 2013.\\n\\nNatalie Geller, 54, was convicted of aiding and abetting an offence under the Terrorism Act 2003 in exchange for providing weapons and intelligence to the Islamic State in Iraq and the Levant (ISIL) in eastern Syria, according to the London crown corporation.\\n\\nGeller was arrested on 9 March 2015 when he fled Syria to Turkey after his home in Essex was raided. Bail was set at £20,000.\\n\\nHe was reported to have been working as a consultant on terrorism issues at the time of his arrest.\\n\\nGeller was charged with conspiracy to supply arms and intelligence to ISIL and encouraging ISIS to carry out attacks in the UK.\\n\\nHe was sentenced to five years\\' concurrent community action for assisting a terrorist organisation and six months\\' concurrent community action for conspiring to supply arms and intelligence to ISIL.\\n\\nThe Crown Prosecution Service (CPS) told the court he was not charged with terrorism because he carried out \"significant activities\" in Syria before his arrest.\\n\\n\"He was working as a consultant on terrorism issues at the time of his arrest,\" CPS said, adding that Geller was believed to have been \"working closely with the bureau of intelligence\" on ISIL.\\n\\n\"The Crown Prosecution Service (CPS) has been concerned about his involvement in ISIL activities for some time and has been providing him with support services,\" it added.\\n\\nThe CPS added that Geller was charged with providing material support to a terrorist organisation, providing material support to an ISIL terrorist organization, or assisting the commission of an offence under the Terrorism Act 2003\".\\n\\nGeller\\'s alleged involvement in terrorist activities was investigated by the CPS following his arrest in November 2013.\\n\\nThe CPS said Geller had been \"at large\" in Syria since December 2014, when he worked as a consultant on terrorism issues at the CIP.\\n\\nThe CPS said Geller continued to work as a consultant on terrorism issues at the CIP until his arrest on 9 September 2015.\\n\\nIn August 2016, he was arrested in Brussels on suspicion of supplying weapons to ISIL in Syria. He was further arrested in March 2017 on suspicion of aiding and abetting an offence under the Terrorism Act 2003.\\n\\nIn April 2017, Geller was arrested in London on suspicion of providing material support to an ISIL terrorist organisation.\\n\\nIn February 2018, the CPS said Geller had been employed by a company investigating ISIL activity in Syria, but no further information was available to the CPS.\\n\\nThe CPS said in May 2018 Geller was arrested on suspicion of assisting a terrorist organisation and was subsequently charged with conspiring to provide material support to a terrorist organisation, providing material support to an ISIL terrorist organization or assisting an ISIL terrorist organization.\\n\\nIn March 2018, the CPS described Geller as working as a consultant for an ISIL terrorist group in Syria.\\n\\nGeller was also charged with conspiring to supply material support to an ISIL terrorist organisation and aiding and abetting an offence under the Terrorism Act 2003.\\n\\nIn October 2018, Geller was arrested in Damascus on suspicion of supplying material support to an ISIL terrorist organisation.\\n\\nIn July 2018, he was arrested in Damascus on suspicion of supplying material support to an ISIL terrorist organisation and assisting and abetting an offence under the Terrorism Act 2003.\\n\\nIn October 2018, Geller was arrested in Damascus on suspicion of assisting a terrorist organisation and providing material support to an ISIL terrorist organisation.\\n\\nGeller was found guilty of supplying material support to an ISIL terrorist organisation and assisting and abetting an offence under the Terrorism Act 2003.\\n\\nGeller was also charged with aiding and abetting an offence under the Act with respect to individuals who were \"committing terrorist acts\" in Syria.\\n\\nThe CPS said his alleged dealings with his former employer were \"part of his ongoing work\" for ISIL and \"he was also involved in the establishment of a foreign terrorist organisation\".\\n\\n\"He worked as a consultant on terrorism issues at the CIP until his arrest on 9 September 2015,\" it added.\\n\\n\"The CPS believes he was involved in the establishment of a foreign terrorist organisation.\"<|endoftext|>In the past few years, psychologists have noted that depressive symptoms are often associated with comorbid mental illness, or with a sense of basic emotional and social needs. A recent study conducted in the United States found that depressed state participants reported more depression than normal participants, but were also more likely to have a history of substance abuse. A recent study conducted in Thailand found that individual differences in depressive symptoms are even stronger among those who report the disturbance of their state, with some 50 percent reporting higher depressive symptoms, while others report higher psychological problems.\\n\\nSeveral researchers have suggested that the relationship between depressive symptoms and mental health is mediated by factors that']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open('single_text.txt', 'w') as f:\n",
        "\t# using csv.writer method from CSV package\n",
        "\twrite = csv.writer(f)\n",
        "\twrite.writerow(single_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "aC7N4MoZAvXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDpaqfbDDMAJ",
        "outputId": "dbed52f7-ba58-4d4f-ee71-10d7b755b0fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Open a CSV file for writing and write the text to it\n",
        "with open('data.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(single_text)\n",
        "\n",
        "print(\"Data exported to data.csv successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTrFwAUEAv87",
        "outputId": "d7cd7db0-b2c2-4a17-bc87-809c3b5c3dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data exported to data.csv successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PqcwF4qFAy1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate Quality of Text:\n"
      ],
      "metadata": {
        "id": "gXYfluAiBlU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KL-Divergence"
      ],
      "metadata": {
        "id": "yScjUjn8MWd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from scipy.stats import entropy\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Read the data from the first CSV file\n",
        "with open('/content/CleanedDatasetEntire1.txt', 'r') as file1:\n",
        "    reader1 = csv.reader(file1)\n",
        "    data1 = [row[0] for row in reader1]\n",
        "\n",
        "# Read the data from the second CSV file\n",
        "with open('/content/Cleaned_Simple_50.txt', 'r') as file2:\n",
        "    reader2 = csv.reader(file2)\n",
        "    data2 = [row[0] for row in reader2]\n",
        "\n",
        "# Convert the strings into a vector representation\n",
        "vectorizer = CountVectorizer()\n",
        "data1_vector = vectorizer.fit_transform(data1)\n",
        "data2_vector = vectorizer.transform(data2)\n",
        "\n",
        "# Convert the vector representation into a numpy array\n",
        "data1_array = data1_vector.toarray().sum(axis=0)\n",
        "data2_array = data2_vector.toarray().sum(axis=0)\n",
        "\n",
        "# Normalize the arrays\n",
        "data1_array = data1_array / data1_array.sum()\n",
        "data2_array = data2_array / data2_array.sum()\n",
        "\n",
        "# Add a small constant to all elements\n",
        "data1_array = data1_array + 1e-10\n",
        "data2_array = data2_array + 1e-10\n",
        "\n",
        "# Normalize the arrays again\n",
        "data1_array = data1_array / data1_array.sum()\n",
        "data2_array = data2_array / data2_array.sum()\n",
        "\n",
        "# Calculate the KL divergence between the two arrays\n",
        "kl_divergence = entropy(data1_array, data2_array)\n",
        "\n",
        "print(\"The KL divergence between the two arrays is:\", kl_divergence)\n",
        "\n",
        "# Plot the arrays using seaborn\n",
        "sns.distplot(data1_array, hist=False, label='GPT-2 generated')\n",
        "sns.distplot(data2_array, hist=False, label='US-Census Entire Dataset')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Probability')\n",
        "plt.title('Distributions of Synthetic  dataset and Original Name Address Dataset')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        },
        "id": "V_ncG1amMY2l",
        "outputId": "a26460b7-96f1-4da6-90d9-cadfca16c614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The KL divergence between the two arrays is: 10.307499597944872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-78-f0cc50c9c2e6>:45: UserWarning: \n",
            "\n",
            "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
            "\n",
            "Please adapt your code to use either `displot` (a figure-level function with\n",
            "similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "\n",
            "For a guide to updating your code to use the new functions, please see\n",
            "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
            "\n",
            "  sns.distplot(data1_array, hist=False, label='GPT-2 generated')\n",
            "<ipython-input-78-f0cc50c9c2e6>:46: UserWarning: \n",
            "\n",
            "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
            "\n",
            "Please adapt your code to use either `displot` (a figure-level function with\n",
            "similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "\n",
            "For a guide to updating your code to use the new functions, please see\n",
            "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
            "\n",
            "  sns.distplot(data2_array, hist=False, label='US-Census Entire Dataset')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4zbzPzKFk_63"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "S7ApLvC4k__n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Wz5niGL3OIzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cosine"
      ],
      "metadata": {
        "id": "MIcuE2VXMhGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import string\n",
        "from collections import Counter\n",
        "\n",
        "def read_file(file_name):\n",
        "    with open(file_name, 'r') as file:\n",
        "        return file.read()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    return text\n",
        "\n",
        "def get_cosine_similarity(text1, text2):\n",
        "    text1 = clean_text(text1)\n",
        "    text2 = clean_text(text2)\n",
        "\n",
        "    words1 = text1.split()\n",
        "    words2 = text2.split()\n",
        "\n",
        "    word_counts1 = Counter(words1)\n",
        "    word_counts2 = Counter(words2)\n",
        "\n",
        "    common_words = set(word_counts1.keys()) & set(word_counts2.keys())\n",
        "\n",
        "    dot_product = sum(word_counts1[word] * word_counts2[word] for word in common_words)\n",
        "    magnitude1 = math.sqrt(sum(word_counts1[word] ** 2 for word in word_counts1.keys()))\n",
        "    magnitude2 = math.sqrt(sum(word_counts2[word] ** 2 for word in word_counts2.keys()))\n",
        "\n",
        "    return dot_product / (magnitude1 * magnitude2)\n",
        "\n",
        "text1 = read_file('CleanedDatasetEntire1.txt')\n",
        "text2 = read_file('single_text.txt')\n",
        "\n",
        "cosine_similarity = get_cosine_similarity(text1, text2)\n",
        "\n",
        "print('Cosine Similarity between Synthetic dataset and original dataset:', cosine_similarity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2_0TsIzBnWy",
        "outputId": "dac79c90-942e-4227-8043-ea067b91aee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity between Synthetic dataset and original dataset: 0.002624086948803878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Levenshtein Distance"
      ],
      "metadata": {
        "id": "0AEw5x5GOZtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLKya2y8OJ3u",
        "outputId": "af580ebc-61ef-4757-dc15-49658550ad7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.23.0-py3-none-any.whl (9.4 kB)\n",
            "Collecting Levenshtein==0.23.0 (from python-Levenshtein)\n",
            "  Downloading Levenshtein-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.1.0 (from Levenshtein==0.23.0->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.23.0 python-Levenshtein-0.23.0 rapidfuzz-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import Levenshtein\n",
        "\n",
        "# Function to read the contents of a text file\n",
        "def read_file(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "# Read the contents of the two files\n",
        "file1_contents = read_file('CleanedDatasetEntire1.txt')\n",
        "file2_contents = read_file('single_text.txt')\n",
        "\n",
        "# Calculate the Levenshtein distance\n",
        "distance = Levenshtein.distance(file1_contents, file2_contents)\n",
        "\n",
        "# Print the result\n",
        "print(f\"Levenshtein distance between the two files: {distance}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHZfrS9wOLA1",
        "outputId": "c1a23b2e-4128-4055-9dd4-26fc806d7750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Levenshtein distance between the two files: 35597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kolmogorov-Smirnov"
      ],
      "metadata": {
        "id": "-bsxdKVmOwCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kBnm0sHhOcoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ks_2samp\n",
        "\n",
        "# Function to read the contents of a text file and calculate the word lengths\n",
        "def calculate_word_lengths(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "        # Split the text into words and calculate word lengths\n",
        "        word_lengths = [len(word) for word in text.split()]\n",
        "        return word_lengths\n",
        "\n",
        "# Read the contents of the two files and calculate word lengths\n",
        "word_lengths1 = calculate_word_lengths('CleanedDatasetEntire1.txt')\n",
        "word_lengths2 = calculate_word_lengths('single_text.txt')\n",
        "\n",
        "# Perform the Kolmogorov-Smirnov test\n",
        "ks_statistic, p_value = ks_2samp(word_lengths1, word_lengths2)\n",
        "\n",
        "# Print the result\n",
        "print(f\"KS Statistic: {ks_statistic}\")\n",
        "print(f\"P-Value: {p_value}\")\n",
        "\n",
        "# Determine the result based on the p-value\n",
        "if p_value < 0.05:\n",
        "    print(\"The distributions are significantly different.\")\n",
        "else:\n",
        "    print(\"The distributions are not significantly different.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv-0XgJ3M4-D",
        "outputId": "b489fdd9-ecb4-47e6-83d9-2b48f77a1aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KS Statistic: 0.19654557741506168\n",
            "P-Value: 2.478757928736684e-25\n",
            "The distributions are significantly different.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pearson Correlation"
      ],
      "metadata": {
        "id": "v5IKHXQBPI3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import math\n",
        "\n",
        "# Function to read the contents of a text file and calculate word frequencies\n",
        "def calculate_word_frequencies(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "        words = text.split()\n",
        "        word_counts = collections.Counter(words)\n",
        "        return word_counts\n",
        "\n",
        "# Read the contents of the two files and calculate word frequencies\n",
        "word_frequencies1 = calculate_word_frequencies('CleanedDatasetEntire1.txt')\n",
        "word_frequencies2 = calculate_word_frequencies('single_text.txt')\n",
        "\n",
        "# Create sets of unique words from both texts\n",
        "unique_words = set(word_frequencies1.keys()).union(word_frequencies2.keys())\n",
        "\n",
        "# Convert word frequencies to a common format, considering words that may be missing\n",
        "word_counts1 = [word_frequencies1[word] if word in word_frequencies1 else 0 for word in unique_words]\n",
        "word_counts2 = [word_frequencies2[word] if word in word_frequencies2 else 0 for word in unique_words]\n",
        "\n",
        "# Calculate the Pearson correlation\n",
        "def pearson_correlation(x, y):\n",
        "    n = len(x)\n",
        "    sum_x = sum(x)\n",
        "    sum_y = sum(y)\n",
        "    sum_x_squared = sum(xi ** 2 for xi in x)\n",
        "    sum_y_squared = sum(yi ** 2 for yi in y)\n",
        "    product_sum = sum(xi * yi for xi, yi in zip(x, y))\n",
        "    numerator = product_sum - (sum_x * sum_y / n)\n",
        "    denominator = math.sqrt((sum_x_squared - (sum_x ** 2 / n)) * (sum_y_squared - (sum_y ** 2 / n)))\n",
        "    if denominator == 0:\n",
        "        return 0  # To handle the case where the denominator is zero\n",
        "    else:\n",
        "        return numerator / denominator\n",
        "\n",
        "correlation = pearson_correlation(word_counts1, word_counts2)\n",
        "\n",
        "# Print the Pearson correlation coefficient\n",
        "print(f\"Pearson Correlation: {correlation}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU4MBfC4O0pK",
        "outputId": "378a94b3-3a57-49d4-ac48-53cae4210c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson Correlation: -0.02636892178042349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Jaccard Distance"
      ],
      "metadata": {
        "id": "WgxvkGlZPNAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read the contents of a text file and tokenize it\n",
        "def tokenize_text(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "        # Tokenize the text by splitting it into words (you can use more advanced tokenization methods if needed)\n",
        "        tokens = set(text.split())\n",
        "        return tokens\n",
        "\n",
        "# Read the contents of the two files and tokenize them\n",
        "tokens1 = tokenize_text('CleanedDatasetEntire1.txt')\n",
        "tokens2 = tokenize_text('single_text.txt')\n",
        "\n",
        "# Calculate the Jaccard similarity\n",
        "intersection = len(tokens1.intersection(tokens2))\n",
        "union = len(tokens1.union(tokens2))\n",
        "\n",
        "jaccard_similarity = intersection / union\n",
        "\n",
        "# Print the Jaccard similarity\n",
        "print(f\"Jaccard Similarity: {jaccard_similarity:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBnWUE3sPWk2",
        "outputId": "8e51a531-9ca4-4862-9998-f5f63ee9807d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard Similarity: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jaccard Similiarity"
      ],
      "metadata": {
        "id": "z_L5DazBPrKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read the contents of a text file and tokenize it\n",
        "def tokenize_text(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "        # Tokenize the text by splitting it into words (you can use more advanced tokenization methods if needed)\n",
        "        tokens = set(text.split())\n",
        "        return tokens\n",
        "\n",
        "# Read the contents of the two files and tokenize them\n",
        "tokens1 = tokenize_text('CleanedDatasetEntire1.txt')\n",
        "tokens2 = tokenize_text('single_text.txt')\n",
        "\n",
        "# Calculate the Jaccard distance\n",
        "intersection = len(tokens1.intersection(tokens2))\n",
        "union = len(tokens1.union(tokens2))\n",
        "\n",
        "jaccard_similarity = intersection / union\n",
        "jaccard_distance = 1 - jaccard_similarity\n",
        "\n",
        "# Print the Jaccard distance\n",
        "print(f\"Jaccard Distance: {jaccard_distance:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpWYGfURPhW5",
        "outputId": "b4aa53c0-e90f-4fa1-8f06-9995d5b37509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard Distance: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVAQGYNKQsa-",
        "outputId": "8edddfc0-0925-4b94-cf76-c1c19a1367e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vfBNSUK6ROhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Word Embedding Similarity"
      ],
      "metadata": {
        "id": "MXQLdnDwUd7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaNMARsSUC8N",
        "outputId": "5676c9b2-c4e3-4541-94c0-fcb99018b373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-27 22:45:48.402884: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-27 22:45:48.402943: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-27 22:45:48.402984: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-27 22:45:49.535676: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-lg==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.6.0/en_core_web_lg-3.6.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "2023-10-27 22:46:22.561172: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-27 22:46:22.561226: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-27 22:46:22.561259: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-27 22:46:23.842669: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy model with word vectors (you can use other models as well)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Read the contents of \"CleanedDatasetEntire1.txt\" and \"single_text.txt\"\n",
        "with open(\"CleanedDatasetEntire1.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text1 = file.read()\n",
        "\n",
        "with open(\"single_text.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text2 = file.read()\n",
        "\n",
        "# Process the text with spaCy\n",
        "doc1 = nlp(text1)\n",
        "doc2 = nlp(text2)\n",
        "\n",
        "# Calculate the similarity between the two documents (cosine similarity)\n",
        "similarity = doc1.similarity(doc2)\n",
        "\n",
        "print(f\"Word Embedding Similarity: {similarity:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZh3kSdVQsu0",
        "outputId": "2b371872-32cd-4054-8afd-4b661b795b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Embedding Similarity: 0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-6c2ad36c846d>:18: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc1.similarity(doc2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BLEU SCORE"
      ],
      "metadata": {
        "id": "GXJJwFz8UwOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv3Ubu-oUx1m",
        "outputId": "3c9ef9cd-1ab3-401e-984b-c5c060a21c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "# Read the contents of \"CleanedDatasetEntire1.txt\" and \"single_text.txt\"\n",
        "with open(\"CleanedDatasetEntire1.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    reference_text = file.read()\n",
        "\n",
        "with open(\"single_text.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    candidate_text = file.read()\n",
        "\n",
        "# Tokenize the reference and candidate texts\n",
        "reference_tokens = nltk.word_tokenize(reference_text)\n",
        "candidate_tokens = nltk.word_tokenize(candidate_text)\n",
        "\n",
        "# Calculate the BLEU Score\n",
        "bleu_score = sentence_bleu([reference_tokens], candidate_tokens)\n",
        "\n",
        "print(f\"BLEU Score: {bleu_score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvUoIUE6Uy6G",
        "outputId": "3bc460a8-56dc-457c-922f-9c223d21aceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Precision, Recall, F-1"
      ],
      "metadata": {
        "id": "wSZgTXYKf5ML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Read the contents of \"CleanedDatasetEntire1.txt\" and \"single_text.txt\"\n",
        "with open(\"CleanedDatasetEntire1.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text1 = file.read()\n",
        "\n",
        "with open(\"single_text.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text2 = file.read()\n",
        "\n",
        "# Assuming you have binary labels (0 for incorrect, 1 for correct) for both texts\n",
        "labels1 = [1, 0]  # Replace with the actual labels for \"CleanedDatasetEntire1.txt\"\n",
        "labels2 = [1, 1]  # Replace with the actual labels for \"single_text.txt\"\n",
        "\n",
        "# Calculate the F1 score, accuracy, precision, and recall\n",
        "f1 = f1_score(labels1, labels2)\n",
        "accuracy = accuracy_score(labels1, labels2)\n",
        "precision = precision_score(labels1, labels2)\n",
        "recall = recall_score(labels1, labels2)\n",
        "\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--AdVg44f7Q-",
        "outputId": "6f0a768c-04a7-4f64-c3b2-d88bef7efc40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.67\n",
            "Accuracy: 0.50\n",
            "Precision: 0.50\n",
            "Recall: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "YwW1AS14fhet"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wQ6Lonn-UCKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM Synthetic dataset"
      ],
      "metadata": {
        "id": "IiO8qbSElAzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# 1. Preprocess the data\n",
        "with open(\"CleanedDatasetEntire1.txt\", \"r\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Convert text to sequences of integers\n",
        "sequences = []\n",
        "for line in text.split(\"\\n\"):\n",
        "    encoded = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(encoded)):\n",
        "        sequences.append(encoded[:i+1])\n",
        "\n",
        "# Pad sequences for consistent length\n",
        "max_length = max([len(seq) for seq in sequences])\n",
        "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
        "\n",
        "# Split sequences into input and output elements\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "\n",
        "# 2. Create an LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=max_length-1))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 3. Train the model\n",
        "model.fit(X, y, epochs=20, verbose=2)\n",
        "\n",
        "# 4. Generate synthetic data\n",
        "def generate_text(seed_text, model, max_length, num_words):\n",
        "    output_text = seed_text\n",
        "    for _ in range(num_words):\n",
        "        encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length-1, padding='pre')\n",
        "        prediction = np.argmax(model.predict(encoded), axis=-1)\n",
        "        predicted_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == prediction:\n",
        "                predicted_word = word\n",
        "                break\n",
        "        seed_text += \" \" + predicted_word\n",
        "        output_text += \" \" + predicted_word\n",
        "    return output_text\n",
        "\n",
        "# Generate new text based on a seed\n",
        "seed = \"This is a\"\n",
        "synthetic_data = generate_text(seed, model, max_length, 500)  # Generating 500 words\n",
        "\n",
        "# Save synthetic data to file\n",
        "with open(\"LSTMtraining.txt\", \"w\") as output_file:\n",
        "    output_file.write(synthetic_data)\n",
        "\n",
        "print(\"Synthetic data saved to LSTMtraining.txt!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhoyJi73lDGL",
        "outputId": "a8a135c3-d8ba-453c-cc05-393c1d218ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 6036 samples\n",
            "Epoch 1/20\n",
            "6036/6036 - 4s - loss: 6.9711 - accuracy: 0.0389 - 4s/epoch - 676us/sample\n",
            "Epoch 2/20\n",
            "6036/6036 - 4s - loss: 6.0570 - accuracy: 0.0570 - 4s/epoch - 685us/sample\n",
            "Epoch 3/20\n",
            "6036/6036 - 4s - loss: 5.5635 - accuracy: 0.1120 - 4s/epoch - 699us/sample\n",
            "Epoch 4/20\n",
            "6036/6036 - 3s - loss: 5.1630 - accuracy: 0.1445 - 3s/epoch - 574us/sample\n",
            "Epoch 5/20\n",
            "6036/6036 - 4s - loss: 4.9143 - accuracy: 0.1589 - 4s/epoch - 587us/sample\n",
            "Epoch 6/20\n",
            "6036/6036 - 5s - loss: 4.7216 - accuracy: 0.1561 - 5s/epoch - 808us/sample\n",
            "Epoch 7/20\n",
            "6036/6036 - 4s - loss: 4.5643 - accuracy: 0.1675 - 4s/epoch - 591us/sample\n",
            "Epoch 8/20\n",
            "6036/6036 - 4s - loss: 4.4288 - accuracy: 0.1718 - 4s/epoch - 585us/sample\n",
            "Epoch 9/20\n",
            "6036/6036 - 4s - loss: 4.3115 - accuracy: 0.2069 - 4s/epoch - 669us/sample\n",
            "Epoch 10/20\n",
            "6036/6036 - 5s - loss: 4.1996 - accuracy: 0.2238 - 5s/epoch - 746us/sample\n",
            "Epoch 11/20\n",
            "6036/6036 - 3s - loss: 4.0976 - accuracy: 0.2399 - 3s/epoch - 577us/sample\n",
            "Epoch 12/20\n",
            "6036/6036 - 3s - loss: 3.9981 - accuracy: 0.2520 - 3s/epoch - 572us/sample\n",
            "Epoch 13/20\n",
            "6036/6036 - 5s - loss: 3.9079 - accuracy: 0.2679 - 5s/epoch - 784us/sample\n",
            "Epoch 14/20\n",
            "6036/6036 - 4s - loss: 3.8240 - accuracy: 0.2813 - 4s/epoch - 583us/sample\n",
            "Epoch 15/20\n",
            "6036/6036 - 3s - loss: 3.7452 - accuracy: 0.2939 - 3s/epoch - 575us/sample\n",
            "Epoch 16/20\n",
            "6036/6036 - 4s - loss: 3.6708 - accuracy: 0.3032 - 4s/epoch - 603us/sample\n",
            "Epoch 17/20\n",
            "6036/6036 - 5s - loss: 3.5971 - accuracy: 0.3091 - 5s/epoch - 780us/sample\n",
            "Epoch 18/20\n",
            "6036/6036 - 3s - loss: 3.5247 - accuracy: 0.3174 - 3s/epoch - 567us/sample\n",
            "Epoch 19/20\n",
            "6036/6036 - 3s - loss: 3.4530 - accuracy: 0.3338 - 3s/epoch - 572us/sample\n",
            "Epoch 20/20\n",
            "6036/6036 - 4s - loss: 3.3805 - accuracy: 0.3441 - 4s/epoch - 712us/sample\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic data saved to LSTMtraining.txt!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BART_Training"
      ],
      "metadata": {
        "id": "GouwIyDvr0Sz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xukGQDCgr33N",
        "outputId": "bb09b622-ea0f-40e1-96bf-57f94e1b6559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qae-L_5ixMZ2",
        "outputId": "7f03ff0f-cb1b-48cd-b668-ba0c335838f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement leakgan (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for leakgan\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPTJForCausalLM, GPT2Tokenizer\n",
        "import torch\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model_name = \"EleutherAI/gpt-j-6B\"\n",
        "model = GPTJForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load the input data\n",
        "with open(\"CleanedDatasetEntire1.txt\", \"r\") as file:\n",
        "    data = file.read()\n",
        "\n",
        "# Tokenize the input data\n",
        "input_ids = tokenizer.encode(data, return_tensors=\"pt\")\n",
        "\n",
        "# Generate synthetic data\n",
        "output = model.generate(input_ids, max_length=1000, num_return_sequences=5, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "# Decode and save the generated data\n",
        "with open(\"GPT-Jtraining.txt\", \"w\") as file:\n",
        "    for item in output:\n",
        "        file.write(tokenizer.decode(item, skip_special_tokens=True) + \"\\n\\n\")\n",
        "\n",
        "print(\"Synthetic data saved to GPT-Jtraining.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "vJ5qd_HWr2WQ",
        "outputId": "e1aa66c9-cc51-425a-8db4-1ae2000bdd9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_is_mode_type\u001b[0;34m(path, mode)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[0;34m(path)\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/usr/local/lib/python3.10/dist-packages/transformers/models/big_bird/__init__.cpython-310-x86_64-linux-gnu.so'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-762fc3ffb279>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPTJForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the model and tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"EleutherAI/gpt-j-6B\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m from . import (\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0malbert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(self, fullname, target)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_isfile\u001b[0;34m(path)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_is_mode_type\u001b[0;34m(path, mode)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PWCx01gwUjco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ciZ9G5DGMwu9"
      }
    }
  ]
}